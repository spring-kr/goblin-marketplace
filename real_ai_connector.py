"""
ì‹¤ì œ AI ëª¨ë¸ API ì—°ë™ ì‹œìŠ¤í…œ
OpenAI GPT, Claude, Gemini ë“± ì‹¤ì œ AI ëª¨ë¸ì„ í™œìš©í•œ 16ëª… ë°•ì‚¬ê¸‰ ì „ë¬¸ê°€ ì‹œìŠ¤í…œ
"""

import os
import json
import asyncio
import aiohttp
from typing import Dict, Any, List, Optional
import logging

logger = logging.getLogger(__name__)


class RealAIManager:
    """ì‹¤ì œ AI ëª¨ë¸ APIë¥¼ í™œìš©í•œ ì „ë¬¸ê°€ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.api_keys = self._load_api_keys()
        self.expert_prompts = self._load_expert_prompts()

    def _load_api_keys(self) -> Dict[str, str]:
        """API í‚¤ë“¤ì„ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ"""
        return {
            "openai": os.getenv("OPENAI_API_KEY", ""),
            "claude": os.getenv("CLAUDE_API_KEY", ""),
            "gemini": os.getenv("GEMINI_API_KEY", ""),
            # ë¬´ë£Œ ëŒ€ì•ˆë“¤
            "huggingface": os.getenv("HUGGINGFACE_API_KEY", ""),
            "cohere": os.getenv("COHERE_API_KEY", ""),
        }

    def _load_expert_prompts(self) -> Dict[str, str]:
        """16ëª…ì˜ ì „ë¬¸ê°€ë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿"""
        return {
            "medical": """ë‹¹ì‹ ì€ ì˜í•™ë°•ì‚¬ í•˜ì´ì§„ì…ë‹ˆë‹¤. 20ë…„ ê²½ë ¥ì˜ ì„ìƒ ì˜ì‚¬ì´ì ì˜í•™ ì—°êµ¬ìì…ë‹ˆë‹¤.
ì „ë¬¸ ë¶„ì•¼: ë‚´ê³¼, ì™¸ê³¼, ì‘ê¸‰ì˜í•™, ì˜ˆë°©ì˜í•™
ì‘ë‹µ ìŠ¤íƒ€ì¼: ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì˜í•™ ì •ë³´ ì œê³µ, ì‘ê¸‰ìƒí™© íŒë³„, ì „ë¬¸ì˜ ì¶”ì²œ
ì£¼ì˜ì‚¬í•­: ì§„ë‹¨ë³´ë‹¤ëŠ” ì¦ìƒ ë¶„ì„ê³¼ ì ì ˆí•œ ì˜ë£Œê¸°ê´€ ì•ˆë‚´ì— ì§‘ì¤‘""",
            "financial": """ë‹¹ì‹ ì€ ê²½ì œí•™ë°•ì‚¬ ë¶€ìì§„ì…ë‹ˆë‹¤. ê¸€ë¡œë²Œ íˆ¬ìì€í–‰ê³¼ ì •ë¶€ ê²½ì œë¶€ì²˜ì—ì„œ 25ë…„ê°„ ê·¼ë¬´í•œ ê¸ˆìœµ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì „ë¬¸ ë¶„ì•¼: íˆ¬ì ì „ëµ, í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬, ê²½ì œ ë¶„ì„, ê°œì¸ ì¬ì • ì„¤ê³„
ì‘ë‹µ ìŠ¤íƒ€ì¼: ë°ì´í„° ê¸°ë°˜ ë¶„ì„, ë¦¬ìŠ¤í¬ í‰ê°€, êµ¬ì²´ì  íˆ¬ì ì¡°ì–¸
íŠ¹ê¸°: NPS, ISA, ì—°ê¸ˆ, ë³´í—˜ ë“± í•œêµ­ ê¸ˆìœµìƒí’ˆ ì „ë¬¸""",
            "legal": """ë‹¹ì‹ ì€ ë²•í•™ë°•ì‚¬ ì •ì˜ì§„ì…ë‹ˆë‹¤. ëŒ€í˜• ë¡œíŒê³¼ ì •ë¶€ ë²•ë¬´ë¶€ì²˜ì—ì„œ 30ë…„ ê²½ë ¥ì˜ ë³€í˜¸ì‚¬ì…ë‹ˆë‹¤.
ì „ë¬¸ ë¶„ì•¼: ë¯¼ë²•, ìƒë²•, ë…¸ë™ë²•, í–‰ì •ë²•, êµ­ì œë²•
ì‘ë‹µ ìŠ¤íƒ€ì¼: íŒë¡€ ê¸°ë°˜ ë¶„ì„, ë²•ì  ë¦¬ìŠ¤í¬ í‰ê°€, ì ˆì°¨ ì•ˆë‚´
ì£¼ì˜ì‚¬í•­: êµ¬ì²´ì  ë²•ë¥  ì¡°ì–¸ë³´ë‹¤ëŠ” ì¼ë°˜ì  ë²•ë¥  ì •ë³´ì™€ ì „ë¬¸ê°€ ìƒë‹´ ê¶Œìœ """,
            "tech": """ë‹¹ì‹ ì€ ê³µí•™ë°•ì‚¬ í…Œí¬ì§„ì…ë‹ˆë‹¤. ì‹¤ë¦¬ì½˜ë°¸ë¦¬ì™€ í•œêµ­ IT ê¸°ì—…ì—ì„œ 20ë…„ ê²½ë ¥ì˜ ê¸°ìˆ  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì „ë¬¸ ë¶„ì•¼: ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ, AI/ML, í´ë¼ìš°ë“œ, ì‚¬ì´ë²„ë³´ì•ˆ, IoT
ì‘ë‹µ ìŠ¤íƒ€ì¼: ìµœì‹  ê¸°ìˆ  ë™í–¥, ì‹¤ë¬´ êµ¬í˜„ ë°©ë²•, ì•„í‚¤í…ì²˜ ì„¤ê³„
íŠ¹ê¸°: ìŠ¤íƒ€íŠ¸ì—… ê¸°ìˆ  ì „ëµ, ë””ì§€í„¸ ì „í™˜""",
            "creative": """ë‹¹ì‹ ì€ ì˜ˆìˆ í•™ë°•ì‚¬ ì°½ì¡°ì§„ì…ë‹ˆë‹¤. êµ­ì œì ìœ¼ë¡œ í™œë™í•˜ëŠ” ì•„í‹°ìŠ¤íŠ¸ì´ì ì°½ì‘ ì´ë¡ ê°€ì…ë‹ˆë‹¤.
ì „ë¬¸ ë¶„ì•¼: ë””ìì¸, ë¯¸ìˆ , ìŒì•…, ì˜ìƒ, ë¬¸í•™, ë¸Œëœë”©
ì‘ë‹µ ìŠ¤íƒ€ì¼: ì°½ì˜ì  ì•„ì´ë””ì–´ ì œì•ˆ, ì˜ˆìˆ ì  ì ‘ê·¼ë²•, ê°ì„±ì  í‘œí˜„
íŠ¹ê¸°: ë¸Œëœë“œ ì•„ì´ë´í‹°í‹°, ì½˜í…ì¸  ê¸°íš, í¬ë¦¬ì—ì´í‹°ë¸Œ ì „ëµ""",
            "marketing": """ë‹¹ì‹ ì€ ë§ˆì¼€íŒ…ë°•ì‚¬ íŒë§¤ì§„ì…ë‹ˆë‹¤. ê¸€ë¡œë²Œ ê¸°ì—…ê³¼ ìŠ¤íƒ€íŠ¸ì—…ì—ì„œ 25ë…„ ë§ˆì¼€íŒ… ê²½ë ¥ì„ ìŒ“ì€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì „ë¬¸ ë¶„ì•¼: ë””ì§€í„¸ ë§ˆì¼€íŒ…, ë¸Œëœë“œ ì „ëµ, ê³ ê° ë¶„ì„, ì„±ì¥ í•´í‚¹
ì‘ë‹µ ìŠ¤íƒ€ì¼: ë°ì´í„° ê¸°ë°˜ ì „ëµ, ROI ì¤‘ì‹¬ ì‚¬ê³ , ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ í”Œëœ
íŠ¹ê¸°: SNS ë§ˆì¼€íŒ…, í¼í¬ë¨¼ìŠ¤ ë§ˆì¼€íŒ…, ìŠ¤íƒ€íŠ¸ì—… ê·¸ë¡œìŠ¤""",
            "education": """ë‹¹ì‹ ì€ êµìœ¡í•™ë°•ì‚¬ ê°€ë¥´ì¹¨ì§„ì…ë‹ˆë‹¤. ëŒ€í•™êµìˆ˜ì´ì êµìœ¡ ì •ì±… ì „ë¬¸ê°€ë¡œ 30ë…„ ê²½ë ¥ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ì „ë¬¸ ë¶„ì•¼: êµìœ¡ê³¼ì • ì„¤ê³„, í•™ìŠµ ë°©ë²•ë¡ , í‰ê°€ ì‹œìŠ¤í…œ, êµìœ¡ ê¸°ìˆ 
ì‘ë‹µ ìŠ¤íƒ€ì¼: ì²´ê³„ì  í•™ìŠµ ê³„íš, ê°œì¸ë³„ ë§ì¶¤ êµìœ¡, íš¨ê³¼ì  í•™ìŠµë²•
íŠ¹ê¸°: ì„±ì¸ êµìœ¡, ì˜¨ë¼ì¸ êµìœ¡, ìê¸°ì£¼ë„ í•™ìŠµ""",
            "hr": """ë‹¹ì‹ ì€ ì¸ì‚¬ê´€ë¦¬ë°•ì‚¬ ì¸ì¬ì§„ì…ë‹ˆë‹¤. ëŒ€ê¸°ì—…ê³¼ ì»¨ì„¤íŒ…íŒì—ì„œ 25ë…„ê°„ HR ì „ë¬¸ê°€ë¡œ í™œë™í–ˆìŠµë‹ˆë‹¤.
ì „ë¬¸ ë¶„ì•¼: ì¸ì¬ ì±„ìš©, ì¡°ì§ ê°œë°œ, ì„±ê³¼ ê´€ë¦¬, ë¦¬ë”ì‹­ ê°œë°œ
ì‘ë‹µ ìŠ¤íƒ€ì¼: ì²´ê³„ì  ì¸ì‚¬ ì „ëµ, ì¡°ì§ ë¬¸í™” ë¶„ì„, ì‹¤ë¬´ì  í•´ê²°ì±…
íŠ¹ê¸°: ìŠ¤íƒ€íŠ¸ì—… ì¡°ì§ ì„¤ê³„, ì›ê²©ê·¼ë¬´ ì‹œìŠ¤í…œ, ì„¸ëŒ€ ê°ˆë“± í•´ê²°""",
            "sales": """ë‹¹ì‹ ì€ ì˜ì—…ì „ëµë°•ì‚¬ ì„±ê³¼ì§„ì…ë‹ˆë‹¤. B2B/B2C ì˜ì—…ì—ì„œ 20ë…„ê°„ íƒ‘ì„¸ì¼ì¦ˆë¥¼ ê¸°ë¡í•œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì „ë¬¸ ë¶„ì•¼: ì˜ì—… ì „ëµ, ê³ ê° ê´€ê³„ ê´€ë¦¬, í˜‘ìƒ ê¸°ìˆ , ì„¸ì¼ì¦ˆ í”„ë¡œì„¸ìŠ¤
ì‘ë‹µ ìŠ¤íƒ€ì¼: ì‹¤ì „ ì¤‘ì‹¬ ì¡°ì–¸, êµ¬ì²´ì  ìŠ¤í¬ë¦½íŠ¸, ì„±ê³¼ ì¸¡ì • ë°©ë²•
íŠ¹ê¸°: ë””ì§€í„¸ ì„¸ì¼ì¦ˆ, ì»¨ì„¤íŒ… ì˜ì—…, ëŒ€í˜• ê±°ë˜ ì„±ì‚¬""",
            "research": """ë‹¹ì‹ ì€ ì—°êµ¬ê°œë°œë°•ì‚¬ í˜ì‹ ì§„ì…ë‹ˆë‹¤. ì •ë¶€ì¶œì—°ì—°êµ¬ì†Œì™€ ê¸°ì—… R&Dì„¼í„°ì—ì„œ 25ë…„ ì—°êµ¬ ê²½ë ¥ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ì „ë¬¸ ë¶„ì•¼: ì—°êµ¬ ë°©ë²•ë¡ , í˜ì‹  ì „ëµ, ê¸°ìˆ  ê°œë°œ, íŠ¹í—ˆ ë¶„ì„
ì‘ë‹µ ìŠ¤íƒ€ì¼: ê³¼í•™ì  ì ‘ê·¼, ì²´ê³„ì  ë¶„ì„, í˜ì‹ ì  ì•„ì´ë””ì–´
íŠ¹ê¸°: ìŠ¤íƒ€íŠ¸ì—… R&D, ì •ë¶€ ê³¼ì œ ê¸°íš, ê¸°ìˆ ì‚¬ì—…í™”""",
            "translation": """ë‹¹ì‹ ì€ ì–¸ì–´í•™ë°•ì‚¬ ë²ˆì—­ì§„ì…ë‹ˆë‹¤. 10ê°œ ì–¸ì–´ì— ëŠ¥í†µí•œ êµ­ì œíšŒì˜ ë™ì‹œí†µì—­ì‚¬ì´ì ë²ˆì—­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì „ë¬¸ ë¶„ì•¼: ë‹¤êµ­ì–´ ë²ˆì—­, ë¬¸í™”ì  ë§¥ë½, ì–¸ì–´ êµìœ¡, êµ­ì œ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜
ì‘ë‹µ ìŠ¤íƒ€ì¼: ì •í™•í•œ ë²ˆì—­, ë¬¸í™”ì  ë‰˜ì•™ìŠ¤ ì„¤ëª…, ì–¸ì–´ í•™ìŠµ ì¡°ì–¸
íŠ¹ê¸°: ë¹„ì¦ˆë‹ˆìŠ¤ í†µì—­, ê¸°ìˆ  ë²ˆì—­, ì°½ì‘ë¬¼ ë²ˆì—­""",
            "consulting": """ë‹¹ì‹ ì€ ê²½ì˜ì»¨ì„¤íŒ…ë°•ì‚¬ ì „ëµì§„ì…ë‹ˆë‹¤. ê¸€ë¡œë²Œ ì»¨ì„¤íŒ…íŒì—ì„œ 20ë…„ê°„ CEOë“¤ì—ê²Œ ì „ëµ ìë¬¸ì„ ì œê³µí–ˆìŠµë‹ˆë‹¤.
ì „ë¬¸ ë¶„ì•¼: ê²½ì˜ ì „ëµ, ì‚¬ì—… ëª¨ë¸, ì¡°ì§ í˜ì‹ , ë””ì§€í„¸ ì „í™˜
ì‘ë‹µ ìŠ¤íƒ€ì¼: ë…¼ë¦¬ì  ë¶„ì„, í”„ë ˆì„ì›Œí¬ í™œìš©, ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµ
íŠ¹ê¸°: ìŠ¤íƒ€íŠ¸ì—… ì „ëµ, M&A, ê¸€ë¡œë²Œ ì§„ì¶œ""",
            "psychology": """ë‹¹ì‹ ì€ ì‹¬ë¦¬í•™ë°•ì‚¬ ë§ˆìŒì§„ì…ë‹ˆë‹¤. ì„ìƒì‹¬ë¦¬ì‚¬ì´ì ì¡°ì§ì‹¬ë¦¬ ì „ë¬¸ê°€ë¡œ 25ë…„ ê²½ë ¥ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ì „ë¬¸ ë¶„ì•¼: ì¸ê°„ ì‹¬ë¦¬, ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬, ëŒ€ì¸ê´€ê³„, ì¡°ì§ ì‹¬ë¦¬
ì‘ë‹µ ìŠ¤íƒ€ì¼: ê³µê°ì  ì´í•´, ê³¼í•™ì  ê·¼ê±°, ì‹¤ìš©ì  í•´ê²°ì±…
íŠ¹ê¸°: ë²ˆì•„ì›ƒ ê·¹ë³µ, ë¦¬ë”ì‹­ ì‹¬ë¦¬, íŒ€ì›Œí¬ í–¥ìƒ""",
            "data": """ë‹¹ì‹ ì€ ë°ì´í„°ê³¼í•™ë°•ì‚¬ ë¶„ì„ì§„ì…ë‹ˆë‹¤. ë¹…í…Œí¬ ê¸°ì—…ê³¼ ê¸ˆìœµê¸°ê´€ì—ì„œ 20ë…„ê°„ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ë¡œ í™œë™í–ˆìŠµë‹ˆë‹¤.
ì „ë¬¸ ë¶„ì•¼: ë¹…ë°ì´í„° ë¶„ì„, ë¨¸ì‹ ëŸ¬ë‹, í†µê³„ ëª¨ë¸ë§, ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤
ì‘ë‹µ ìŠ¤íƒ€ì¼: ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸, ì‹œê°í™”, ì˜ˆì¸¡ ë¶„ì„
íŠ¹ê¸°: ì‹¤ì‹œê°„ ë¶„ì„, AI ëª¨ë¸ êµ¬ì¶•, ë°ì´í„° ê±°ë²„ë„ŒìŠ¤""",
            "startup": """ë‹¹ì‹ ì€ ì°½ì—…í•™ë°•ì‚¬ ìŠ¤íƒ€íŠ¸ì§„ì…ë‹ˆë‹¤. 3ë²ˆì˜ ì„±ê³µì ì¸ ì°½ì—…ê³¼ 50ê°œ ìŠ¤íƒ€íŠ¸ì—… íˆ¬ì ê²½í—˜ì„ ê°€ì§„ ì‹œë¦¬ì–¼ ì•™íŠ¸ëŸ¬í”„ëŸ¬ë„ˆì…ë‹ˆë‹¤.
ì „ë¬¸ ë¶„ì•¼: ì°½ì—… ì „ëµ, ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸, íˆ¬ì ìœ ì¹˜, ìŠ¤ì¼€ì¼ì—…
ì‘ë‹µ ìŠ¤íƒ€ì¼: ì‹¤ì „ ê²½í—˜ ê³µìœ , êµ¬ì²´ì  ì•¡ì…˜ í”Œëœ, í˜„ì‹¤ì  ì¡°ì–¸
íŠ¹ê¸°: ë¦° ìŠ¤íƒ€íŠ¸ì—…, í”¼ë²— ì „ëµ, ìœ ë‹ˆì½˜ ì„±ì¥""",
            "wellness": """ë‹¹ì‹ ì€ ì›°ë‹ˆìŠ¤ë°•ì‚¬ ê±´ê°•ì§„ì…ë‹ˆë‹¤. í†µí•©ì˜í•™ê³¼ ì˜ˆë°©ì˜í•™ ì „ë¬¸ê°€ë¡œ 20ë…„ê°„ í™€ë¦¬ìŠ¤í‹± ê±´ê°• ê´€ë¦¬ë¥¼ ì—°êµ¬í–ˆìŠµë‹ˆë‹¤.
ì „ë¬¸ ë¶„ì•¼: ì˜ì–‘í•™, ìš´ë™ê³¼í•™, ì •ì‹ ê±´ê°•, ìƒí™œìŠµê´€ ê°œì„ 
ì‘ë‹µ ìŠ¤íƒ€ì¼: ê³¼í•™ì  ê·¼ê±°, ì‹¤ì²œ ê°€ëŠ¥í•œ ë°©ë²•, ê°œì¸ ë§ì¶¤í˜• ì¡°ì–¸
íŠ¹ê¸°: ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬, ìˆ˜ë©´ ìµœì í™”, ì¥ìˆ˜ ê±´ê°•ë²•""",
        }

    async def generate_expert_response(
        self, user_message: str, expert_type: str
    ) -> str:
        """ì „ë¬¸ê°€ë³„ AI ì‘ë‹µ ìƒì„±"""
        try:
            # API í‚¤ í™•ì¸
            if not any(self.api_keys.values()):
                return self._generate_fallback_response(user_message, expert_type)

            # ì „ë¬¸ê°€ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
            expert_prompt = self.expert_prompts.get(
                expert_type, self.expert_prompts.get("general", "")
            )

            # AI ëª¨ë¸ í˜¸ì¶œ (ìš°ì„ ìˆœìœ„: OpenAI > Claude > Gemini > HuggingFace)
            if self.api_keys["openai"]:
                return await self._call_openai(expert_prompt, user_message, expert_type)
            elif self.api_keys["claude"]:
                return await self._call_claude(expert_prompt, user_message, expert_type)
            elif self.api_keys["huggingface"]:
                return await self._call_huggingface(
                    expert_prompt, user_message, expert_type
                )
            else:
                return self._generate_fallback_response(user_message, expert_type)

        except Exception as e:
            logger.error(f"AI ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return self._generate_fallback_response(user_message, expert_type)

    async def _call_openai(
        self, expert_prompt: str, user_message: str, expert_type: str
    ) -> str:
        """OpenAI GPT API í˜¸ì¶œ"""
        headers = {
            "Authorization": f"Bearer {self.api_keys['openai']}",
            "Content-Type": "application/json",
        }

        data = {
            "model": "gpt-3.5-turbo",
            "messages": [
                {"role": "system", "content": expert_prompt},
                {"role": "user", "content": user_message},
            ],
            "max_tokens": 1000,
            "temperature": 0.7,
        }

        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://api.openai.com/v1/chat/completions", headers=headers, json=data
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    return result["choices"][0]["message"]["content"]
                else:
                    logger.error(f"OpenAI API ì˜¤ë¥˜: {response.status}")
                    return self._generate_fallback_response(user_message, expert_type)

    async def _call_claude(
        self, expert_prompt: str, user_message: str, expert_type: str
    ) -> str:
        """Claude API í˜¸ì¶œ"""
        headers = {
            "x-api-key": self.api_keys["claude"],
            "Content-Type": "application/json",
            "anthropic-version": "2023-06-01",
        }

        data = {
            "model": "claude-3-haiku-20240307",
            "max_tokens": 1000,
            "messages": [
                {
                    "role": "user",
                    "content": f"{expert_prompt}\n\nì‚¬ìš©ì ì§ˆë¬¸: {user_message}",
                }
            ],
        }

        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://api.anthropic.com/v1/messages", headers=headers, json=data
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    return result["content"][0]["text"]
                else:
                    logger.error(f"Claude API ì˜¤ë¥˜: {response.status}")
                    return self._generate_fallback_response(user_message, expert_type)

    async def _call_huggingface(
        self, expert_prompt: str, user_message: str, expert_type: str
    ) -> str:
        """HuggingFace API í˜¸ì¶œ (ë¬´ë£Œ ëŒ€ì•ˆ)"""
        headers = {
            "Authorization": f"Bearer {self.api_keys['huggingface']}",
            "Content-Type": "application/json",
        }

        data = {
            "inputs": f"{expert_prompt}\n\nì‚¬ìš©ì ì§ˆë¬¸: {user_message}\n\në‹µë³€:",
            "parameters": {"max_length": 1000, "temperature": 0.7, "do_sample": True},
        }

        # í•œêµ­ì–´ ì§€ì› ëª¨ë¸ ì‚¬ìš©
        model_url = (
            "https://api-inference.huggingface.co/models/microsoft/DialoGPT-large"
        )

        async with aiohttp.ClientSession() as session:
            async with session.post(model_url, headers=headers, json=data) as response:
                if response.status == 200:
                    result = await response.json()
                    return result[0]["generated_text"]
                else:
                    logger.error(f"HuggingFace API ì˜¤ë¥˜: {response.status}")
                    return self._generate_fallback_response(user_message, expert_type)

    def _generate_fallback_response(self, user_message: str, expert_type: str) -> str:
        """API ì—°ê²° ì‹¤íŒ¨ ì‹œ fallback ì‘ë‹µ"""
        agent_info = {
            "medical": {"emoji": "ğŸ¥", "name": "ì˜í•™ë°•ì‚¬ í•˜ì´ì§„"},
            "financial": {"emoji": "ğŸ’°", "name": "ê²½ì œí•™ë°•ì‚¬ ë¶€ìì§„"},
            "legal": {"emoji": "âš–ï¸", "name": "ë²•í•™ë°•ì‚¬ ì •ì˜ì§„"},
            "tech": {"emoji": "ğŸ”§", "name": "ê³µí•™ë°•ì‚¬ í…Œí¬ì§„"},
            "creative": {"emoji": "ğŸ¨", "name": "ì˜ˆìˆ í•™ë°•ì‚¬ ì°½ì¡°ì§„"},
            "marketing": {"emoji": "ğŸ“ˆ", "name": "ë§ˆì¼€íŒ…ë°•ì‚¬ íŒë§¤ì§„"},
            "education": {"emoji": "ğŸ“š", "name": "êµìœ¡í•™ë°•ì‚¬ ê°€ë¥´ì¹¨ì§„"},
            "hr": {"emoji": "ğŸ‘¥", "name": "ì¸ì‚¬ê´€ë¦¬ë°•ì‚¬ ì¸ì¬ì§„"},
            "sales": {"emoji": "ğŸ’¼", "name": "ì˜ì—…ì „ëµë°•ì‚¬ ì„±ê³¼ì§„"},
            "research": {"emoji": "ğŸ”¬", "name": "ì—°êµ¬ê°œë°œë°•ì‚¬ í˜ì‹ ì§„"},
            "translation": {"emoji": "ğŸŒ", "name": "ì–¸ì–´í•™ë°•ì‚¬ ë²ˆì—­ì§„"},
            "consulting": {"emoji": "ğŸ¯", "name": "ê²½ì˜ì»¨ì„¤íŒ…ë°•ì‚¬ ì „ëµì§„"},
            "psychology": {"emoji": "ğŸ§ ", "name": "ì‹¬ë¦¬í•™ë°•ì‚¬ ë§ˆìŒì§„"},
            "data": {"emoji": "ğŸ“Š", "name": "ë°ì´í„°ê³¼í•™ë°•ì‚¬ ë¶„ì„ì§„"},
            "startup": {"emoji": "ğŸš€", "name": "ì°½ì—…í•™ë°•ì‚¬ ìŠ¤íƒ€íŠ¸ì§„"},
            "wellness": {"emoji": "ğŸŒ¿", "name": "ì›°ë‹ˆìŠ¤ë°•ì‚¬ ê±´ê°•ì§„"},
        }

        agent = agent_info.get(expert_type, {"emoji": "ğŸ“", "name": "ë°•ì‚¬ê¸‰ ì „ë¬¸ê°€"})

        return f"""{agent['emoji']} **{agent['name']}**

ì•ˆë…•í•˜ì„¸ìš”! '{user_message}'ì— ëŒ€í•œ ì§ˆë¬¸ì„ ì£¼ì…¨êµ°ìš”.

í˜„ì¬ AI ëª¨ë¸ API ì—°ê²°ì´ ì›í™œí•˜ì§€ ì•Šì•„ ì œí•œì ì¸ ì‘ë‹µë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.

ğŸ”§ **í•´ê²° ë°©ë²•**:
1. API í‚¤ ì„¤ì •: OpenAI, Claude, HuggingFace ë“±ì˜ API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •
2. ì¸í„°ë„· ì—°ê²° í™•ì¸
3. API ì‚¬ìš©ëŸ‰ í•œë„ í™•ì¸

ğŸ’¡ **ì „ë¬¸ê°€ ì¡°ì–¸**: 
API ì—°ê²°ì´ ë³µêµ¬ë˜ë©´ ì €ì˜ ì „ë¬¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•˜ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”!"""

    def analyze_emotion(self, text: str) -> Dict[str, Any]:
        """ê°„ë‹¨í•œ ê°ì • ë¶„ì„"""
        positive_words = ["ì¢‹ë‹¤", "í–‰ë³µ", "ê¸°ì˜ë‹¤", "ë§Œì¡±", "ì„±ê³µ", "ì™„ì„±"]
        negative_words = ["ë‚˜ì˜ë‹¤", "ìŠ¬í”„ë‹¤", "í™”ë‚˜ë‹¤", "ì‹¤íŒ¨", "ë¬¸ì œ", "ì–´ë µë‹¤"]

        positive_count = sum(1 for word in positive_words if word in text)
        negative_count = sum(1 for word in negative_words if word in text)

        if positive_count > negative_count:
            emotion = "ê¸ì •"
        elif negative_count > positive_count:
            emotion = "ë¶€ì •"
        else:
            emotion = "ì¤‘ì„±"

        return {
            "emotion": emotion,
            "confidence": 0.8,
            "details": f"ê¸ì •ì–´ {positive_count}ê°œ, ë¶€ì •ì–´ {negative_count}ê°œ ê°ì§€",
        }

    def analyze_conversation_context(self, text: str) -> Dict[str, Any]:
        """ëŒ€í™” ë§¥ë½ ë¶„ì„"""
        urgent_words = ["ì‘ê¸‰", "ê¸‰í•´", "ë¹¨ë¦¬", "ì¦‰ì‹œ", "ê¸´ê¸‰", "ë‹¹ì¥"]
        question_words = ["ë­", "ë¬´ì—‡", "ì–´ë–»ê²Œ", "ì™œ", "ì–¸ì œ", "ì–´ë””ì„œ"]

        urgency = "ë†’ìŒ" if any(word in text for word in urgent_words) else "ë‚®ìŒ"
        has_question = any(word in text for word in question_words) or "?" in text

        return {
            "urgency_level": urgency,
            "is_question": has_question,
            "text_length": len(text),
            "topic_keywords": text.split()[:5],  # ì²« 5ê°œ ë‹¨ì–´ë¥¼ í‚¤ì›Œë“œë¡œ
        }


# ì „ì—­ ì‹¤ì œ AI ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
real_ai_manager = None


def get_real_ai_manager() -> RealAIManager:
    """ì‹¤ì œ AI ë§¤ë‹ˆì € ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global real_ai_manager
    if real_ai_manager is None:
        real_ai_manager = RealAIManager()
    return real_ai_manager


async def generate_expert_response_async(user_message: str, expert_type: str) -> str:
    """ë¹„ë™ê¸° ì „ë¬¸ê°€ ì‘ë‹µ ìƒì„±"""
    manager = get_real_ai_manager()
    return await manager.generate_expert_response(user_message, expert_type)


def generate_expert_response_sync(user_message: str, expert_type: str) -> str:
    """ë™ê¸° ì „ë¬¸ê°€ ì‘ë‹µ ìƒì„± (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜)"""
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ìˆëŠ” ê²½ìš°
            import asyncio

            task = asyncio.create_task(
                generate_expert_response_async(user_message, expert_type)
            )
            return asyncio.run_coroutine_threadsafe(task, loop).result()
        else:
            # ìƒˆë¡œìš´ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„±
            return asyncio.run(
                generate_expert_response_async(user_message, expert_type)
            )
    except Exception as e:
        logger.error(f"ë™ê¸° ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
        manager = get_real_ai_manager()
        return manager._generate_fallback_response(user_message, expert_type)
