"""
ğŸš€ ê³ ê¸‰ ë„ê¹¨ë¹„ ì–´ëŒ‘í„° v11.0 - 32ëª… ì „ë¬¸ê°€ & ì‹¤ì‹œê°„ í•™ìŠµ
==========================================================

v10.1 â†’ v11.0 ì—…ê·¸ë ˆì´ë“œ:
- 32ëª… ì „ë¬¸ê°€ ì§€ì›
- ì‹¤ì‹œê°„ í”¼ë“œë°± í•™ìŠµ
- ì—°ì† ëŒ€í™” ê´€ë¦¬
- ìƒí™©ë³„ ë§ì¶¤ ì‘ë‹µ
"""

from advanced_memory_system_v11 import (
    AdvancedMemorySystem,
    ConversationMode,
    FeedbackType,
    ConversationContext,
)
from typing import Dict, Any, List, Optional
import time
import asyncio


class AdvancedGoblinAdapter:
    """ê³ ê¸‰ ë„ê¹¨ë¹„ ì–´ëŒ‘í„° v11.0"""

    def __init__(self, goblin_name: str):
        """ì–´ëŒ‘í„° ì´ˆê¸°í™”"""
        self.goblin_name = goblin_name
        self.memory_system = AdvancedMemorySystem(
            f"{goblin_name}_advanced_memory_v11.json"
        )
        self.active_contexts: Dict[str, ConversationContext] = {}

        print(f"ğŸš€ {goblin_name} ê³ ê¸‰ ì–´ëŒ‘í„° v11.0 ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ğŸ‘¥ 32ëª… ì „ë¬¸ê°€ ì‹œìŠ¤í…œ í™œì„±í™”")

    async def process_advanced_message(
        self,
        user_id: str,
        message: str,
        conversation_id: Optional[str] = None,
        mode: ConversationMode = ConversationMode.SINGLE,
        topic: Optional[str] = None,
    ) -> Dict[str, Any]:
        """ê³ ê¸‰ ë©”ì‹œì§€ ì²˜ë¦¬ (v11.0)"""

        if not conversation_id:
            conversation_id = f"{user_id}_{int(time.time())}"

        # ğŸ”„ ì—°ì† ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
        context = self._get_or_create_context(
            conversation_id, mode, topic or "ì¼ë°˜ ëŒ€í™”"
        )

        # ğŸ§  ê°ì • ë¶„ì„ (ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì—ì„œ ë¶„ì„ ê¸°ëŠ¥ ì‚¬ìš©)
        emotion = self._analyze_emotion(message)

        # ğŸ¯ ìµœì  ì „ë¬¸ê°€ ì„ íƒ (3-5ëª…)
        selected_experts = self.memory_system.select_best_experts(
            message, emotion, context
        )

        # ğŸ’« ë‹¤ì¤‘ ì „ë¬¸ê°€ ì‘ë‹µ ìƒì„±
        expert_responses = await self._generate_multi_expert_responses(
            message, selected_experts, context
        )

        # ğŸ”€ ìµœì  ì‘ë‹µ í•©ì„±
        final_response = self._synthesize_responses(expert_responses, context)

        # ğŸ“ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
        primary_expert = selected_experts[0] if selected_experts else "general"
        self.memory_system.update_conversation_context(
            conversation_id, message, final_response, primary_expert, emotion
        )

        # ğŸ“Š ì‘ë‹µ ë°ì´í„° êµ¬ì„±
        response_data = {
            "response": final_response,
            "emotion": emotion,
            "selected_experts": selected_experts,
            "expert_responses": expert_responses,
            "conversation_mode": mode.value,
            "context_progress": context.progress,
            "expert_chain": context.expert_chain,
            "learning_insights": self.memory_system.get_learning_insights(),
            "conversation_id": conversation_id,
            "timestamp": time.time(),
        }

        return response_data

    def _analyze_emotion(self, message: str) -> str:
        """ê°ì • ë¶„ì„ (v11.0 í˜¸í™˜)"""
        # ê°„ë‹¨í•œ ê°ì • ë¶„ì„ êµ¬í˜„
        emotion_keywords = {
            "ê¸°ì¨": ["ê¸°ì˜", "í–‰ë³µ", "ì¢‹ì•„", "ê°ì‚¬", "ë§Œì¡±", "ì‹ ë‚˜", "ì¦ê±°"],
            "ìŠ¬í””": ["ìŠ¬í”„", "ìš°ìš¸", "í˜ë“¤", "ì•„í”„", "ê´´ë¡œ", "ëˆˆë¬¼", "ì ˆë§"],
            "ë¶„ë…¸": ["í™”ë‚˜", "ì§œì¦", "ë¶„ë…¸", "ì—´ë°›", "ë¹¡ì¹˜", "ì–µìš¸", "ê´˜ë…"],
            "ë¶ˆì•ˆ": ["ê±±ì •", "ë¶ˆì•ˆ", "ë‘ë ¤", "ë¬´ì„œ", "ê¸´ì¥", "ìŠ¤íŠ¸ë ˆìŠ¤"],
            "í˜¸ê¸°ì‹¬": ["ê¶ê¸ˆ", "ì•Œê³  ì‹¶", "ê´€ì‹¬", "í¥ë¯¸", "ì‹ ê¸°", "ì–´ë–»ê²Œ"],
            "í™•ì‹ ": ["í™•ì‹¤", "ë¶„ëª…", "í‹€ë¦¼ì—†", "í™•ì‹ ", "ë‹¹ì—°"],
            "ì˜êµ¬ì‹¬": ["ì˜ì‹¬", "í™•ì‹¤í•˜ì§€", "ì •ë§", "ì§„ì§œ", "í˜¹ì‹œ"],
            "ë†€ëŒ": ["ë†€ë¼", "ê¹œì§", "ì–´ë¨¸", "í—‰", "ì™€"],
            "ì°¨ë¶„í•¨": ["ì°¨ë¶„", "í‰ì˜¨", "ì•ˆì •", "ê³ ìš”", "í¸ì•ˆ"],
        }

        message_lower = message.lower()
        for emotion, keywords in emotion_keywords.items():
            if any(keyword in message_lower for keyword in keywords):
                return emotion

        return "ì¤‘ë¦½"

    def _get_or_create_context(
        self, conversation_id: Optional[str], mode: ConversationMode, topic: str
    ) -> ConversationContext:
        """ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±"""

        # conversation_idê°€ Noneì¸ ê²½ìš° ìƒˆë¡œ ìƒì„±
        if conversation_id is None:
            conversation_id = f"auto_{int(time.time())}"

        if conversation_id in self.memory_system.context_sessions:
            return self.memory_system.context_sessions[conversation_id]

        # ìƒˆ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = self.memory_system.create_conversation_context(
            conversation_id, mode, topic
        )

        return context

    async def _generate_multi_expert_responses(
        self, message: str, experts: List[str], context: ConversationContext
    ) -> Dict[str, str]:
        """ë‹¤ì¤‘ ì „ë¬¸ê°€ ì‘ë‹µ ìƒì„±"""

        responses = {}

        for expert in experts:
            try:
                # ì „ë¬¸ê°€ë³„ íŠ¹í™” ì‘ë‹µ ìƒì„±
                expert_response = self.memory_system.generate_contextual_response(
                    message, expert, context
                )
                responses[expert] = expert_response

                # ì§§ì€ ì§€ì—° (ì‹¤ì œ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜)
                await asyncio.sleep(0.1)

            except Exception as e:
                print(f"âš ï¸ {expert} ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
                responses[expert] = "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

        return responses

    def _synthesize_responses(
        self, expert_responses: Dict[str, str], context: ConversationContext
    ) -> str:
        """ì „ë¬¸ê°€ ì‘ë‹µ í•©ì„±"""

        if not expert_responses:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # 1. ì£¼ ì‘ë‹µ ì„ íƒ (ì²« ë²ˆì§¸ ì „ë¬¸ê°€)
        primary_expert = list(expert_responses.keys())[0]
        primary_response = expert_responses[primary_expert]

        # 2. ë‹¨ì¼ ì „ë¬¸ê°€ì¸ ê²½ìš°
        if len(expert_responses) == 1:
            return primary_response

        # 3. ë‹¤ì¤‘ ì „ë¬¸ê°€ ì˜ê²¬ í†µí•©
        if context.mode == ConversationMode.DEEP_DIVE:
            return self._create_comprehensive_response(expert_responses)
        elif context.mode == ConversationMode.CREATIVE:
            return self._create_creative_synthesis(expert_responses)
        else:
            return self._create_balanced_response(expert_responses)

    def _create_comprehensive_response(self, responses: Dict[str, str]) -> str:
        """ì¢…í•©ì  ì‘ë‹µ ìƒì„± (ì‹¬í™” íƒêµ¬ ëª¨ë“œ)"""

        expert_names = list(responses.keys())
        main_response = responses[expert_names[0]]

        additional_perspectives = []
        for expert in expert_names[1:3]:  # ìµœëŒ€ 3ê°œ ê´€ì 
            expert_info = self.memory_system.experts.get(expert, {})
            expert_name = expert_info.get("name", expert)
            additional_perspectives.append(f"{expert_name}: {responses[expert]}")

        if additional_perspectives:
            synthesis = f"{main_response}\n\nğŸ” ì¶”ê°€ ì „ë¬¸ê°€ ì˜ê²¬:\n"
            synthesis += "\n".join(additional_perspectives)
            return synthesis

        return main_response

    def _create_creative_synthesis(self, responses: Dict[str, str]) -> str:
        """ì°½ì˜ì  ì‘ë‹µ í•©ì„± (ì°½ì˜ í˜‘ì—… ëª¨ë“œ)"""

        # ëª¨ë“  ì‘ë‹µì„ ì°½ì˜ì ìœ¼ë¡œ ìœµí•©
        all_responses = list(responses.values())

        synthesis = "ğŸ’¡ ì°½ì˜ì  ìœµí•© ê´€ì :\n\n"
        synthesis += f"{all_responses[0]}"

        if len(all_responses) > 1:
            synthesis += f"\n\nğŸ¨ ë˜í•œ, {all_responses[1]}"

        if len(all_responses) > 2:
            synthesis += f"\n\nâœ¨ ë” ë‚˜ì•„ê°€, {all_responses[2]}"

        return synthesis

    def _create_balanced_response(self, responses: Dict[str, str]) -> str:
        """ê· í˜•ì¡íŒ ì‘ë‹µ ìƒì„± (ì¼ë°˜ ëª¨ë“œ)"""

        primary_response = list(responses.values())[0]

        # ê°„ë‹¨í•œ ì¶”ê°€ ì˜ê²¬ (ìµœëŒ€ 1ê°œ)
        if len(responses) > 1:
            secondary_expert = list(responses.keys())[1]
            secondary_response = responses[secondary_expert]
            expert_info = self.memory_system.experts.get(secondary_expert, {})
            expert_name = expert_info.get("name", secondary_expert)

            return f"{primary_response}\n\nğŸ’­ {expert_name}ì˜ ì¶”ê°€ ì˜ê²¬: {secondary_response}"

        return primary_response

    def add_user_feedback(
        self,
        conversation_id: str,
        message_id: str,
        rating: int,
        feedback_type: str = "general",
        comment: Optional[str] = None,
    ):
        """ì‚¬ìš©ì í”¼ë“œë°± ì¶”ê°€"""

        # ë¬¸ìì—´ì„ FeedbackTypeìœ¼ë¡œ ë³€í™˜
        feedback_map = {
            "positive": FeedbackType.POSITIVE,
            "negative": FeedbackType.NEGATIVE,
            "helpful": FeedbackType.HELPFUL,
            "irrelevant": FeedbackType.IRRELEVANT,
            "more_detail": FeedbackType.MORE_DETAIL,
            "simpler": FeedbackType.SIMPLER,
            "general": FeedbackType.POSITIVE if rating >= 4 else FeedbackType.NEGATIVE,
        }

        feedback_type_enum = feedback_map.get(feedback_type, FeedbackType.POSITIVE)

        self.memory_system.add_feedback(
            conversation_id, message_id, feedback_type_enum, rating, comment or ""
        )

        print(f"ğŸ“ í”¼ë“œë°± ì²˜ë¦¬ ì™„ë£Œ: {rating}ì  ({feedback_type})")

    def get_conversation_summary(self, conversation_id: str) -> Dict[str, Any]:
        """ëŒ€í™” ìš”ì•½ ì¡°íšŒ"""

        if conversation_id not in self.memory_system.context_sessions:
            return {"error": "ëŒ€í™” ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}

        context = self.memory_system.context_sessions[conversation_id]

        summary = {
            "conversation_id": conversation_id,
            "mode": context.mode.value,
            "topic": context.topic,
            "progress": context.progress,
            "expert_chain": context.expert_chain,
            "total_exchanges": len(context.context_history),
            "duration": (
                time.time() - context.context_history[0]["timestamp"]
                if context.context_history
                else 0
            ),
            "last_updated": context.last_updated,
        }

        return summary

    def recommend_next_actions(self, conversation_id: str) -> List[str]:
        """ë‹¤ìŒ í–‰ë™ ì¶”ì²œ"""

        if conversation_id not in self.memory_system.context_sessions:
            return ["ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”."]

        context = self.memory_system.context_sessions[conversation_id]
        recommendations = []

        # ì§„í–‰ë„ ê¸°ë°˜ ì¶”ì²œ
        if context.progress < 0.3:
            recommendations.append("ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”")
            recommendations.append("ê´€ì‹¬ ìˆëŠ” ì„¸ë¶€ ë¶„ì•¼ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”")
        elif context.progress < 0.7:
            recommendations.append("ë‹¤ë¥¸ ê´€ì ì—ì„œ ì ‘ê·¼í•´ë³¼ê¹Œìš”?")
            recommendations.append("ì‹¤ì œ ì ìš© ë°©ì•ˆì„ ë…¼ì˜í•´ë³´ì„¸ìš”")
        else:
            recommendations.append("ê²°ë¡ ì„ ì •ë¦¬í•´ë³¼ê¹Œìš”?")
            recommendations.append("ì¶”ê°€ í•™ìŠµ ìë£Œë¥¼ ìš”ì²­í•´ë³´ì„¸ìš”")

        # ì „ë¬¸ê°€ ì²´ì¸ ê¸°ë°˜ ì¶”ì²œ
        if len(context.expert_chain) == 1:
            recommendations.append("ë‹¤ë¥¸ ì „ë¬¸ê°€ì˜ ì˜ê²¬ë„ ë“¤ì–´ë³´ì„¸ìš”")

        return recommendations[:3]  # ìµœëŒ€ 3ê°œ

    def get_expert_performance(self) -> Dict[str, Any]:
        """ì „ë¬¸ê°€ ì„±ëŠ¥ ì¡°íšŒ"""

        insights = self.memory_system.get_learning_insights()
        expert_stats = {}

        for expert_id, expert_info in self.memory_system.experts.items():
            expert_stats[expert_id] = {
                "name": expert_info["name"],
                "field": expert_info["field"],
                "level": expert_info["level"],
                "usage_count": self.memory_system.expert_performance.get(
                    expert_id, {}
                ).get("usage_count", 0),
                "avg_rating": self.memory_system.expert_performance.get(
                    expert_id, {}
                ).get("avg_rating", 0.0),
            }

        return {
            "total_experts": len(self.memory_system.experts),
            "expert_details": expert_stats,
            "system_insights": insights,
        }


# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸
async def test_advanced_adapter():
    """ê³ ê¸‰ ì–´ëŒ‘í„° í…ŒìŠ¤íŠ¸"""

    adapter = AdvancedGoblinAdapter("advanced_test")

    print("ğŸ§ª ê³ ê¸‰ ì–´ëŒ‘í„° v11.0 í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)

    # 1. ë‹¨ì¼ ëŒ€í™” í…ŒìŠ¤íŠ¸
    print("\nğŸ“ ë‹¨ì¼ ëŒ€í™” í…ŒìŠ¤íŠ¸:")
    result1 = await adapter.process_advanced_message(
        "user123",
        "ì¸ê³µì§€ëŠ¥ê³¼ ì–‘ìì»´í“¨íŒ…ì˜ ë¯¸ë˜ì— ëŒ€í•´ ì•Œê³  ì‹¶ì–´ìš”",
        mode=ConversationMode.SINGLE,
    )

    print(f"ğŸ¤– ì‘ë‹µ: {result1['response'][:100]}...")
    print(f"ğŸ¯ ì„ íƒëœ ì „ë¬¸ê°€: {result1['selected_experts']}")
    print(f"ğŸ˜Š ê°ì •: {result1['emotion']}")

    # 2. ì—°ì† ëŒ€í™” í…ŒìŠ¤íŠ¸
    print("\nğŸ”„ ì—°ì† ëŒ€í™” í…ŒìŠ¤íŠ¸:")
    conversation_id = result1["conversation_id"]

    result2 = await adapter.process_advanced_message(
        "user123",
        "ì¢€ ë” êµ¬ì²´ì ì¸ ì‘ìš© ë¶„ì•¼ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”",
        conversation_id=conversation_id,
        mode=ConversationMode.CONTINUOUS,
    )

    print(f"ğŸ¤– ì‘ë‹µ: {result2['response'][:100]}...")
    print(f"ğŸ¯ ì „ë¬¸ê°€ ì²´ì¸: {result2['expert_chain']}")
    print(f"ğŸ“Š ì§„í–‰ë„: {result2['context_progress']:.1%}")

    # 3. í”¼ë“œë°± í…ŒìŠ¤íŠ¸
    print("\nğŸ“ í”¼ë“œë°± í…ŒìŠ¤íŠ¸:")
    adapter.add_user_feedback(
        conversation_id, "msg_001", 5, "helpful", "ì •ë§ ìœ ìš©í–ˆì–´ìš”!"
    )

    # 4. ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    print("\nğŸ’¡ ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸:")
    recommendations = adapter.recommend_next_actions(conversation_id)
    print(f"ì¶”ì²œ í–‰ë™: {recommendations}")

    # 5. ëŒ€í™” ìš”ì•½
    print("\nğŸ“‹ ëŒ€í™” ìš”ì•½:")
    summary = adapter.get_conversation_summary(conversation_id)
    print(f"ëŒ€í™” ì£¼ì œ: {summary['topic']}")
    print(f"ì°¸ì—¬ ì „ë¬¸ê°€: {summary['expert_chain']}")
    print(f"ì§„í–‰ë„: {summary['progress']:.1%}")

    # 6. ì „ë¬¸ê°€ ì„±ëŠ¥
    print("\nğŸ‘¥ ì „ë¬¸ê°€ ì„±ëŠ¥:")
    performance = adapter.get_expert_performance()
    print(f"ì´ ì „ë¬¸ê°€ ìˆ˜: {performance['total_experts']}")
    print(f"ì‹œìŠ¤í…œ ì¸ì‚¬ì´íŠ¸: {performance['system_insights']}")


if __name__ == "__main__":
    asyncio.run(test_advanced_adapter())
