"""
ğŸ¯ Korean BERT ê°ì •ë¶„ì„ í†µí•© ì‹œìŠ¤í…œ + ì‚¬ìš©ì ë§ì¶¤í˜• ëª¨ë¸ ì§€ì›
ì‚¬ìš©ìì˜ ê°ì •ì„ ì •í™•íˆ ë¶„ì„í•˜ì—¬ ë„ê¹¨ë¹„ë“¤ì´ ë§ì¶¤í˜• ì‘ë‹µì„ ì œê³µí•˜ëŠ” ì‹œìŠ¤í…œ
"""

import re
import random
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime


class KoreanEmotionAnalyzer:
    """Korean BERT ê¸°ë°˜ ê°ì •ë¶„ì„ê¸° + ì‚¬ìš©ì ëª¨ë¸ ì§€ì›"""

    def __init__(self):
        self.emotion_model = None
        self.tokenizer = None
        self.custom_model = None
        self.emotion_labels = ["ê¸°ì¨", "ìŠ¬í””", "ë¶„ë…¸", "ë¶ˆì•ˆ", "ë†€ëŒ", "í˜ì˜¤", "ì¤‘ë¦½"]
        self.emotion_intensities = ["ë‚®ìŒ", "ë³´í†µ", "ë†’ìŒ"]

        # ì‚¬ìš©ì ë§ì¶¤í˜• ëª¨ë¸ ìš°ì„  ë¡œë“œ ì‹œë„
        self._init_custom_model()

        # ì‚¬ìš©ì ëª¨ë¸ì´ ì—†ìœ¼ë©´ BERT ëª¨ë¸ ì‹œë„
        if not self.custom_model:
            self._init_emotion_model()

    def _init_custom_model(self):
        """ì‚¬ìš©ì ë§ì¶¤í˜• ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            from custom_emotion_model import CustomEmotionModelLoader
            
            # ëª¨ë¸ ê²½ë¡œë“¤ ì‹œë„ (ìƒˆ íŒŒì´í”„ë¼ì¸ ìš°ì„ )
            model_paths = [
                "./models/korean_emotion_complete_pipeline.pkl",  # ìƒˆë¡œ ìƒì„±ëœ íŒŒì´í”„ë¼ì¸
                "./models/korean_bert_emotion_pipeline.pkl",  # ëŒ€ì²´ íŒŒì´í”„ë¼ì¸
                "./models/korean_bert_emotion.pkl",  # ê¸°ì¡´ ëª¨ë¸
                "./models/",  # ë””ë ‰í† ë¦¬ ê²½ë¡œ
                "./models/trained_models/",  # í›ˆë ¨ëœ ëª¨ë¸ ë””ë ‰í† ë¦¬
            ]
            
            for model_path in model_paths:
                try:
                    print(f"ğŸ” ëª¨ë¸ ë¡œë“œ ì‹œë„: {model_path}")
                    loader = CustomEmotionModelLoader(model_path)
                    if loader.is_loaded:
                        self.custom_model = loader
                        print(f"âœ… ì‚¬ìš©ì ë§ì¶¤í˜• ê°ì •ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì„±ê³µ! ({model_path})")
                        return True
                except Exception as e:
                    print(f"âš ï¸ {model_path} ë¡œë“œ ì‹¤íŒ¨: {e}")
                    continue
            
            print("âš ï¸ ì‚¬ìš©ì ëª¨ë¸ ì—†ìŒ, ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©")
            return False
            
        except ImportError:
            print("âš ï¸ ì‚¬ìš©ì ëª¨ë¸ ë¡œë” ì—†ìŒ")
            return False

    def _init_emotion_model(self):
        """ê°ì •ë¶„ì„ ëª¨ë¸ ì´ˆê¸°í™” (BERT ë°±ì—…)"""
        try:
            # Korean BERT ëª¨ë¸ ë¡œë“œ ì‹œë„ (transformersê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
            try:
                import torch
                from transformers import (
                    AutoTokenizer,
                    AutoModelForSequenceClassification,
                )

                # í•œêµ­ì–´ ê°ì •ë¶„ì„ ëª¨ë¸ (ì˜ˆì‹œ: monologg/kobert)
                model_name = "monologg/kobert"  # ë˜ëŠ” ë‹¤ë¥¸ í•œêµ­ì–´ ê°ì •ë¶„ì„ ëª¨ë¸

                self.tokenizer = AutoTokenizer.from_pretrained(model_name)
                self.emotion_model = AutoModelForSequenceClassification.from_pretrained(
                    model_name
                )
                print("âœ… Korean BERT ê°ì •ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
            except Exception as e:
                print(f"âš ï¸ BERT ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, ê·œì¹™ê¸°ë°˜ ë¶„ì„ ì‚¬ìš©: {e}")
                self.emotion_model = None

        except ImportError:
            print("âš ï¸ transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ, ê·œì¹™ê¸°ë°˜ ê°ì •ë¶„ì„ ì‚¬ìš©")
            self.emotion_model = None

    def analyze_emotion(self, text: str) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„ (ì‚¬ìš©ì ëª¨ë¸ ìš°ì„ )"""
        # 1. ì‚¬ìš©ì ë§ì¶¤í˜• ëª¨ë¸ ìš°ì„  ì‚¬ìš©
        if self.custom_model and self.custom_model.is_loaded:
            try:
                result = self.custom_model.predict_emotion(text)
                print(f"ğŸ¯ ì‚¬ìš©ì ëª¨ë¸ ì‚¬ìš©: {result.get('analysis_method', 'Custom')}")
                
                # ë°˜í™˜ ê°’ êµ¬ì¡° í†µì¼
                return {
                    "emotion": result.get("primary_emotion", result.get("emotion", "ì¤‘ë¦½")),
                    "confidence": result.get("confidence", 0.5),
                    "intensity": result.get("intensity", "ë³´í†µ"),
                    "method": result.get("analysis_method", "Custom_Model"),
                    "emotion_scores": result.get("all_emotions", result.get("emotion_scores", {}))
                }
            except Exception as e:
                print(f"âš ï¸ ì‚¬ìš©ì ëª¨ë¸ ì‹¤íŒ¨, ë°±ì—… ëª¨ë¸ ì‚¬ìš©: {e}")

        # 2. BERT ëª¨ë¸ ì‚¬ìš©
        if self.emotion_model and self.tokenizer:
            try:
                result = self._bert_emotion_analysis(text)
                return {
                    "emotion": result.get("primary_emotion", "ì¤‘ë¦½"),
                    "confidence": result.get("confidence", 0.5),
                    "intensity": result.get("intensity", "ë³´í†µ"),
                    "method": result.get("analysis_method", "BERT"),
                    "emotion_scores": result.get("all_emotions", {})
                }
            except Exception as e:
                print(f"âš ï¸ BERT ëª¨ë¸ ì‹¤íŒ¨, ê·œì¹™ ê¸°ë°˜ ì‚¬ìš©: {e}")

        # 3. ìµœì¢… ë°±ì—…: ê·œì¹™ ê¸°ë°˜ ë¶„ì„
        result = self._rule_based_emotion_analysis(text)
        return {
            "emotion": result.get("primary_emotion", "ì¤‘ë¦½"),
            "confidence": result.get("confidence", 0.5),
            "intensity": result.get("intensity", "ë³´í†µ"),
            "method": result.get("analysis_method", "Rule_Based"),
            "emotion_scores": result.get("all_emotions", {})
        }

    def _bert_emotion_analysis(self, text: str) -> Dict[str, Any]:
        """BERT ëª¨ë¸ì„ ì‚¬ìš©í•œ ê³ ê¸‰ ê°ì •ë¶„ì„"""
        try:
            import torch

            # í† í°í™” ë° ì˜ˆì¸¡ ìˆ˜í–‰
            if self.tokenizer and self.emotion_model:
                inputs = self.tokenizer(
                    text,
                    return_tensors="pt",
                    truncation=True,
                    padding=True,
                    max_length=512,
                )

                # ê°ì • ì˜ˆì¸¡
                with torch.no_grad():
                    outputs = self.emotion_model(**inputs)
                    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)

                # ê²°ê³¼ í•´ì„
                emotion_scores = predictions[0].numpy()
                primary_emotion_idx = np.argmax(emotion_scores)
                primary_emotion = self.emotion_labels[primary_emotion_idx]
                confidence = float(emotion_scores[primary_emotion_idx])

                # ê°•ë„ ê³„ì‚°
                intensity = (
                    "ë†’ìŒ"
                    if confidence > 0.7
                    else "ë³´í†µ" if confidence > 0.4 else "ë‚®ìŒ"
                )

                return {
                    "primary_emotion": primary_emotion,
                    "confidence": confidence,
                    "intensity": intensity,
                    "all_emotions": dict(
                        zip(self.emotion_labels, emotion_scores.tolist())
                    ),
                    "analysis_method": "BERT",
                }
            else:
                raise Exception("BERT ëª¨ë¸ ë˜ëŠ” í† í¬ë‚˜ì´ì €ê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ")

        except Exception as e:
            print(f"BERT ë¶„ì„ ì˜¤ë¥˜: {e}")
            return self._rule_based_emotion_analysis(text)

    def _rule_based_emotion_analysis(self, text: str) -> Dict[str, Any]:
        """ê·œì¹™ ê¸°ë°˜ ê°ì •ë¶„ì„ (ë°±ì—…ìš©)"""
        text = text.lower()

        # ê°ì •ë³„ í‚¤ì›Œë“œ ì •ì˜
        emotion_keywords = {
            "ê¸°ì¨": [
                "ê¸°ì˜",
                "í–‰ë³µ",
                "ì¢‹ì•„",
                "ì¦ê±°",
                "ì›ƒìŒ",
                "ì‹ ë‚˜",
                "ìµœê³ ",
                "êµ¿",
                "ì¢‹ë„¤",
                "ë©‹ì§€",
                "ì™„ë²½",
                "ì‚¬ë‘",
            ],
            "ìŠ¬í””": [
                "ìŠ¬í”„",
                "ìš°ìš¸",
                "í˜ë“¤",
                "ì•„í”„",
                "ëˆˆë¬¼",
                "ê´´ë¡œ",
                "ì ˆë§",
                "ì™¸ë¡œ",
                "í—ˆë¬´",
                "ë¹„ì°¸",
            ],
            "ë¶„ë…¸": [
                "í™”ë‚˜",
                "ì§œì¦",
                "ë¶„ë…¸",
                "ì—´ë°›",
                "ë¹¡ì¹˜",
                "ì‹«ì–´",
                "ë¯¸ì›Œ",
                "ì•…",
                "ê°œë¹¡",
                "ì–´ì´ì—†",
            ],
            "ë¶ˆì•ˆ": [
                "ê±±ì •",
                "ë¶ˆì•ˆ",
                "ë¬´ì„œ",
                "ë‘ë ¤",
                "ë–¨ë ¤",
                "ê¸´ì¥",
                "ìŠ¤íŠ¸ë ˆìŠ¤",
                "ì••ë°•",
                "ê³ ë¯¼",
            ],
            "ë†€ëŒ": [
                "ë†€ë¼",
                "ê¹œì§",
                "ì–´ë¨¸",
                "í—‰",
                "ì™€",
                "ëŒ€ë°•",
                "ì§„ì§œ",
                "ì„¤ë§ˆ",
                "ì–´ë–»ê²Œ",
            ],
            "í˜ì˜¤": ["ì—­ê²¨", "ì§•ê·¸", "ë”ëŸ¬", "ë”ì°", "ì‹«", "ê±°ë¶€ê°", "ëª»ì°¸"],
            "ì¤‘ë¦½": ["ê·¸ëƒ¥", "ë³´í†µ", "í‰ë²”", "ì¼ë°˜", "ìŒ", "ì•„", "ë„¤", "ì˜ˆ"],
        }

        # ê°•ë„ë³„ í‚¤ì›Œë“œ
        intensity_keywords = {
            "ë†’ìŒ": [
                "ë„ˆë¬´",
                "ì •ë§",
                "ì§„ì§œ",
                "ì™„ì „",
                "ì—„ì²­",
                "ë§¤ìš°",
                "êµ‰ì¥íˆ",
                "ìµœê³ ë¡œ",
                "ê·¹ë„ë¡œ",
            ],
            "ë³´í†µ": ["ì¢€", "ì¡°ê¸ˆ", "ì•½ê°„", "ì–´ëŠì •ë„", "ê·¸ëŸ­ì €ëŸ­"],
            "ë‚®ìŒ": ["ì‚´ì§", "ê°€ë³ê²Œ", "ì•½ê°„", "ì¡°ê¸ˆë§Œ"],
        }

        # ê°ì • ì ìˆ˜ ê³„ì‚°
        emotion_scores = {}
        for emotion, keywords in emotion_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text)
            emotion_scores[emotion] = score

        # ì£¼ìš” ê°ì • ê²°ì •
        if sum(emotion_scores.values()) == 0:
            primary_emotion = "ì¤‘ë¦½"
            confidence = 0.5
        else:
            primary_emotion = max(
                emotion_scores.keys(), key=lambda k: emotion_scores[k]
            )
            total_matches = sum(emotion_scores.values())
            confidence = (
                emotion_scores[primary_emotion] / total_matches
                if total_matches > 0
                else 0.5
            )

        # ê°•ë„ ê²°ì •
        intensity = "ë‚®ìŒ"
        for level, keywords in intensity_keywords.items():
            if any(keyword in text for keyword in keywords):
                intensity = level
                break

        return {
            "primary_emotion": primary_emotion,
            "confidence": confidence,
            "intensity": intensity,
            "all_emotions": emotion_scores,
            "analysis_method": "Rule-based",
        }


class EmotionalResponseGenerator:
    """ê°ì • ê¸°ë°˜ ì‘ë‹µ ìƒì„±ê¸°"""

    def __init__(self):
        self.emotion_analyzer = KoreanEmotionAnalyzer()
        self.emotion_responses = self._init_emotion_responses()
        self.empathy_phrases = self._init_empathy_phrases()

    def _init_emotion_responses(self) -> Dict[str, Dict[str, List[str]]]:
        """ê°ì •ë³„ ì‘ë‹µ íŒ¨í„´"""
        return {
            "ê¸°ì¨": {
                "greeting": [
                    "ì™€! ì •ë§ ê¸°ìœ ë§ˆìŒì´ ì „í•´ì ¸ìš”! ğŸ˜„",
                    "í–‰ë³µí•œ ì—ë„ˆì§€ê°€ ëŠê»´ì§€ë„¤ìš”! âœ¨",
                    "ê¸°ë¶„ ì¢‹ì€ ì†Œì‹ì¸ê°€ ë´ìš”! ğŸ‰",
                ],
                "response": [
                    "ì €ë„ ë©ë‹¬ì•„ ê¸°ë¶„ì´ ì¢‹ì•„ì ¸ìš”!",
                    "ì´ëŸ° ê¸ì •ì ì¸ ì—ë„ˆì§€ ì •ë§ ì¢‹ì•„í•´ìš”!",
                    "í•¨ê»˜ ê¸°ë»í•  ìˆ˜ ìˆì–´ì„œ í–‰ë³µí•´ìš”!",
                ],
            },
            "ìŠ¬í””": {
                "greeting": [
                    "ë§ˆìŒì´ ë§ì´ í˜ë“œì‹œê² ì–´ìš”... ğŸ’™",
                    "ì–´ë ¤ìš´ ì‹œê°„ì„ ë³´ë‚´ê³  ê³„ì‹œëŠ”êµ°ìš”... ğŸ¤—",
                    "ë§ì´ ì†ìƒí•˜ì…¨ì„ ê²ƒ ê°™ì•„ìš”...",
                ],
                "response": [
                    "ì–¸ì œë“  ì´ì•¼ê¸°í•˜ê³  ì‹¶ìœ¼ì‹œë©´ ë“¤ì–´ë“œë¦´ê²Œìš”.",
                    "í˜¼ìê°€ ì•„ë‹ˆì—ìš”, ì œê°€ ì—¬ê¸° ìˆì–´ìš”.",
                    "ì²œì²œíˆ ë§ˆìŒì„ í„¸ì–´ë†“ìœ¼ì…”ë„ ë¼ìš”.",
                ],
            },
            "ë¶„ë…¸": {
                "greeting": [
                    "ë§ì´ í™”ê°€ ë‚˜ì…¨ë‚˜ ë´ìš”... ğŸ˜¤",
                    "ì •ë§ ë‹µë‹µí•˜ê³  ì§œì¦ë‚˜ëŠ” ìƒí™©ì´ì—ˆê² ì–´ìš”...",
                    "ê·¸ëŸ° ê¸°ë¶„ ì¶©ë¶„íˆ ì´í•´í•´ìš”...",
                ],
                "response": [
                    "í™”ê°€ ë‚˜ëŠ” ê±´ ë‹¹ì—°í•´ìš”. ì–´ë–¤ ì¼ì´ì—ˆëŠ”ì§€ ë§ì”€í•´ì£¼ì„¸ìš”.",
                    "ë¶„ë…¸ì˜ ì›ì¸ì„ ì°¾ì•„ì„œ í•´ê²°ì±…ì„ ìƒê°í•´ë´ìš”.",
                    "ìŠ¤íŠ¸ë ˆìŠ¤ í•´ì†Œ ë°©ë²•ì„ í•¨ê»˜ ì°¾ì•„ë³¼ê¹Œìš”?",
                ],
            },
            "ë¶ˆì•ˆ": {
                "greeting": [
                    "ê±±ì •ì´ ë§ìœ¼ì‹œê² ì–´ìš”... ğŸ˜”",
                    "ë¶ˆì•ˆí•œ ë§ˆìŒ ì •ë§ ì˜ ì•Œê² ì–´ìš”...",
                    "ë§ˆìŒì´ í¸í•˜ì§€ ì•Šìœ¼ì‹œì£ ...",
                ],
                "response": [
                    "ì²œì²œíˆ í˜¸í¡í•˜ë©° ì°¨ê·¼ì°¨ê·¼ í•´ê²°í•´ë´ìš”.",
                    "ê±±ì •ì„ ë‚˜ëˆ„ë©´ ë¶€ë‹´ì´ ì¤„ì–´ë“¤ ê±°ì˜ˆìš”.",
                    "í•¨ê»˜ ì°¨ê·¼ì°¨ê·¼ ì •ë¦¬í•´ë³´ë©´ ê´œì°®ì„ ê±°ì˜ˆìš”.",
                ],
            },
            "ë†€ëŒ": {
                "greeting": [
                    "ì™€! ì •ë§ ë†€ë¼ìš´ ì¼ì´ ìˆì—ˆë‚˜ë´ìš”! ğŸ˜²",
                    "ì–´ë–¤ ë†€ë¼ìš´ ì¼ì´ ìˆì—ˆëŠ”ì§€ ê¶ê¸ˆí•´ìš”!",
                    "ê¹œì§ ë†€ë¼ì…¨ê² ì–´ìš”!",
                ],
                "response": [
                    "ìì„¸í•œ ì´ì•¼ê¸°ê°€ ì •ë§ ê¶ê¸ˆí•´ìš”!",
                    "ì–´ë–¤ ì¼ì¸ì§€ ë” ë“¤ë ¤ì£¼ì„¸ìš”!",
                    "ì •ë§ í¥ë¯¸ì§„ì§„í•˜ë„¤ìš”!",
                ],
            },
            "ì¤‘ë¦½": {
                "greeting": [
                    "ì•ˆë…•í•˜ì„¸ìš”! í¸ì•ˆí•œ ë§ˆìŒìœ¼ë¡œ ëŒ€í™”í•´ìš” ğŸ˜Š",
                    "ì°¨ë¶„í•œ ë¶„ìœ„ê¸°ë„¤ìš”. ì¢‹ì•„ìš”!",
                    "í‰ì˜¨í•œ ë§ˆìŒìœ¼ë¡œ ì´ì•¼ê¸° ë‚˜ëˆ ë´ìš”.",
                ],
                "response": [
                    "ë¬´ì—‡ì´ë“  í¸í•˜ê²Œ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”.",
                    "ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ìš”.",
                    "ì²œì²œíˆ ëŒ€í™”í•´ë´ìš”.",
                ],
            },
        }

    def _init_empathy_phrases(self) -> Dict[str, List[str]]:
        """ê³µê° í‘œí˜„"""
        return {
            "ì´í•´": [
                "ì •ë§ ì˜ ì´í•´í•´ìš”",
                "ê·¸ëŸ° ë§ˆìŒ ì¶©ë¶„íˆ ê³µê°í•´ìš”",
                "ë‹¹ì—°íˆ ê·¸ëŸ´ ìˆ˜ ìˆì–´ìš”",
                "ì™„ì „íˆ ì´í•´ë©ë‹ˆë‹¤",
            ],
            "ì§€ì§€": [
                "í•­ìƒ ì‘ì›í•˜ê³  ìˆì–´ìš”",
                "í•¨ê»˜ í•´ê²°í•´ë‚˜ê°€ìš”",
                "í˜¼ìê°€ ì•„ë‹ˆì—ìš”",
                "ì œê°€ ë„ì™€ë“œë¦´ê²Œìš”",
            ],
            "ê²©ë ¤": ["ì˜ í•˜ê³  ê³„ì„¸ìš”", "ì¶©ë¶„íˆ í›Œë¥­í•´ìš”", "ê´œì°®ì„ ê±°ì˜ˆìš”", "í˜ë‚´ì„¸ìš”"],
        }

    def generate_emotional_response(
        self, text: str, agent_type: str, base_response: str
    ) -> str:
        """ê°ì •ì„ ê³ ë ¤í•œ ì‘ë‹µ ìƒì„±"""
        # ê°ì • ë¶„ì„
        emotion_result = self.emotion_analyzer.analyze_emotion(text)
        primary_emotion = emotion_result["primary_emotion"]
        intensity = emotion_result["intensity"]
        confidence = emotion_result["confidence"]

        # ê°ì •ë³„ ì‘ë‹µ íŒ¨í„´ ê°€ì ¸ì˜¤ê¸°
        emotion_patterns = self.emotion_responses.get(
            primary_emotion, self.emotion_responses["ì¤‘ë¦½"]
        )

        # ê°ì • ì¸ì‚¬ë§
        emotional_greeting = ""
        if confidence > 0.3:  # ì¶©ë¶„íˆ í™•ì‹¤í•œ ê°ì •ì¸ ê²½ìš°ë§Œ
            greeting_options = emotion_patterns.get("greeting", [])
            if greeting_options:
                emotional_greeting = random.choice(greeting_options) + "\n\n"

        # ê³µê° í‘œí˜„ ì¶”ê°€
        empathy_phrase = ""
        if primary_emotion in ["ìŠ¬í””", "ë¶„ë…¸", "ë¶ˆì•ˆ"] and confidence > 0.4:
            empathy_type = "ì´í•´" if primary_emotion == "ìŠ¬í””" else "ì§€ì§€"
            empathy_options = self.empathy_phrases.get(empathy_type, [])
            if empathy_options:
                empathy_phrase = random.choice(empathy_options) + " "

        # ê°•ë„ì— ë”°ë¥¸ ì‘ë‹µ ì¡°ì •
        if intensity == "ë†’ìŒ" and confidence > 0.6:
            base_response = self._intensify_response(base_response, primary_emotion)

        # ìµœì¢… ì‘ë‹µ êµ¬ì„±
        final_response = emotional_greeting + empathy_phrase + base_response

        # ê°ì •ë³„ ë§ˆë¬´ë¦¬ ë¬¸êµ¬
        emotion_endings = emotion_patterns.get("response", [])
        if emotion_endings and confidence > 0.4:
            ending = random.choice(emotion_endings)
            final_response += f"\n\n{ending}"

        return final_response

    def _intensify_response(self, response: str, emotion: str) -> str:
        """ê°•í•œ ê°ì •ì— ëŒ€í•œ ì‘ë‹µ ê°•í™”"""
        if emotion == "ê¸°ì¨":
            return response.replace("!", "!! ğŸ‰").replace(".", "! âœ¨")
        elif emotion == "ìŠ¬í””":
            return "ì •ë§ " + response + " ë§ˆìŒì´ ì•„íŒŒìš”..."
        elif emotion == "ë¶„ë…¸":
            return "ì™„ì „íˆ ì´í•´í•´ìš”. " + response + " ì •ë§ í™”ë‚˜ì‹¤ ë§Œí•´ìš”."
        elif emotion == "ë¶ˆì•ˆ":
            return "ê±±ì • ë§ˆì„¸ìš”. " + response + " í•¨ê»˜ í•´ê²°í•´ë´ìš”."
        else:
            return response


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
emotional_responder = EmotionalResponseGenerator()


def get_emotional_response(
    text: str, agent_type: str, base_response: str
) -> Tuple[str, Dict[str, Any]]:
    """ê°ì •ë¶„ì„ ê¸°ë°˜ ì‘ë‹µ ìƒì„± (ì™¸ë¶€ í˜¸ì¶œìš©)"""
    enhanced_response = emotional_responder.generate_emotional_response(
        text, agent_type, base_response
    )
    emotion_analysis = emotional_responder.emotion_analyzer.analyze_emotion(text)

    return enhanced_response, emotion_analysis


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    test_texts = [
        "ì˜¤ëŠ˜ ì •ë§ ê¸°ë¶„ì´ ì¢‹ì•„ìš”! ì¢‹ì€ ì¼ì´ ìˆì—ˆê±°ë“ ìš”",
        "ë„ˆë¬´ ìŠ¬í”„ê³  ìš°ìš¸í•´ìš”... í˜ë“  ì¼ì´ ìˆì—ˆì–´ìš”",
        "ì •ë§ í™”ê°€ ë‚˜ìš”! ì´í•´í•  ìˆ˜ ì—†ì–´ìš”",
        "ê±±ì •ì´ ë„ˆë¬´ ë§ì•„ì„œ ì ë„ ëª» ìê² ì–´ìš”",
        "ì•ˆë…•í•˜ì„¸ìš”, ë„ì›€ì´ í•„ìš”í•´ìš”",
    ]

    print("ğŸ¯ Korean BERT ê°ì •ë¶„ì„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\n")

    for text in test_texts:
        response, analysis = get_emotional_response(
            text, "counselor", "ë„ì›€ì´ ë˜ë„ë¡ ìµœì„ ì„ ë‹¤í•˜ê² ìŠµë‹ˆë‹¤."
        )

        print(f"ì…ë ¥: {text}")
        print(
            f"ê°ì •: {analysis['primary_emotion']} (í™•ì‹ ë„: {analysis['confidence']:.2f}, ê°•ë„: {analysis['intensity']})"
        )
        print(f"ì‘ë‹µ: {response}")
        print("-" * 80)
