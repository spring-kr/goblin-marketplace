"""
ğŸ¯ AI ë„ê¹¨ë¹„ë§ˆì„ STEM ì„¼í„° - ì‹¤ì œ AI ëŒ€í™” ì‹œìŠ¤í…œ
ì§„ì§œ AIì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê³  ë§¥ë½ì ì¸ ì‘ë‹µì„ ì œê³µí•˜ëŠ” 16ê°œ ë„ê¹¨ë¹„ ì‹œìŠ¤í…œ
"""

import random
from datetime import datetime
from typing import Dict, Any, Optional
import hashlib
import json
import os


class STEMIntegration:
    """STEM ë„ê¹¨ë¹„ë“¤ê³¼ì˜ ì‹¤ì œ AI ëŒ€í™” ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.system_name = "ğŸ° ë„ê¹¨ë¹„ë§ˆì„ì¥í„° ë°•ì‚¬ê¸‰ AI ìƒë‹´ì†Œ"
        # ëŒ€í™” ê¸°ë¡ ì €ì¥ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬ (ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ì €ì¥)
        self.conversation_history = {}
        self.context_file = "conversation_context.json"
        self._load_conversation_history()

    def _load_conversation_history(self):
        """ëŒ€í™” ê¸°ë¡ ë¡œë“œ"""
        try:
            if os.path.exists(self.context_file):
                with open(self.context_file, "r", encoding="utf-8") as f:
                    self.conversation_history = json.load(f)
        except Exception:
            self.conversation_history = {}

    def _save_conversation_history(self):
        """ëŒ€í™” ê¸°ë¡ ì €ì¥"""
        try:
            with open(self.context_file, "w", encoding="utf-8") as f:
                json.dump(self.conversation_history, f, ensure_ascii=False, indent=2)
        except Exception:
            pass

    def _get_conversation_key(self, user_ip: str, agent_type: str) -> str:
        """ì‚¬ìš©ì-ì—ì´ì „íŠ¸ë³„ ëŒ€í™” í‚¤ ìƒì„±"""
        key = f"{user_ip}_{agent_type}"
        return hashlib.md5(key.encode()).hexdigest()[:16]

    def _analyze_follow_up_intent(self, question: str, previous_topics: list) -> dict:
        """í›„ì† ì§ˆë¬¸ ì˜ë„ ë¶„ì„ - ê°„ë‹¨ ê·œì¹™ ê¸°ë°˜"""
        q = (question or "").strip().lower()

        indicators = {
            "more_detail": ["êµ¬ì²´ì ìœ¼ë¡œ", "ë” ìì„¸íˆ", "ì„¸ë¶€", "ìƒì„¸"],
            "example": ["ì˜ˆì‹œ", "ì‚¬ë¡€", "ì˜ˆë¥¼ ë“¤ì–´"],
            "how_to": ["ì–´ë–»ê²Œ", "ë°©ë²•", "ë‹¨ê³„", "ì ˆì°¨"],
            "advanced": ["ê³ ê¸‰", "ì‹¬í™”", "ì „ë¬¸", "ë” ê¹Šì´"],
            "practical": ["ì‹¤ë¬´", "í˜„ì‹¤ì ", "ë°”ë¡œ", "ì‹¤í–‰"],
        }

        intent = "general"
        for k, words in indicators.items():
            if any(w in q for w in words):
                intent = k
                break

        # ê°„ë‹¨í•œ follow-up ì‹ í˜¸
        follow_signals = [
            "ë‹¤ì‹œ",
            "ì´ì–´",
            "ì¶”ê°€",
            "ë”",
            "ê³„ì†",
            "ì•ì—ì„œ",
            "ë°©ê¸ˆ",
            "ìœ„ ë‚´ìš©",
        ]
        is_follow_up = False
        if previous_topics:
            recent_topics = [
                t.lower() for t in previous_topics[-3:] if isinstance(t, str)
            ]
            if any(sig in q for sig in follow_signals) or any(
                t and t in q for t in recent_topics
            ):
                is_follow_up = True

        depth_level = 1 + min(2, len(previous_topics)) if is_follow_up else 1

        return {
            "is_follow_up": is_follow_up,
            "intent": intent,
            "depth_level": depth_level,
        }

    def process_question(
        self, agent_type: str, question: str, user_ip: str
    ) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬ (ë™ì  ì‘ë‹µ)"""
        try:
            try:
                from usage_tracker import usage_tracker  # ì§€í‘œ ê¸°ë¡
            except Exception:
                usage_tracker = None

            info_map = self.get_agent_info().get("agents", {})
            if agent_type not in info_map:
                if usage_tracker:
                    usage_tracker.log_usage(agent_type, question, False, user_ip)
                return {
                    "success": False,
                    "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì—ì´ì „íŠ¸ íƒ€ì…: {agent_type}",
                }

            if not question or len(question.strip()) < 2:
                if usage_tracker:
                    usage_tracker.log_usage(agent_type, question, False, user_ip)
                return {
                    "success": False,
                    "error": "ì§ˆë¬¸ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìµœì†Œ 2ê¸€ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.",
                }

            conversation_key = self._get_conversation_key(user_ip, agent_type)
            previous_conversations = self.conversation_history.get(conversation_key, [])
            previous_topics = [c.get("topic", "") for c in previous_conversations]

            follow_up = self._analyze_follow_up_intent(question, previous_topics)

            info = info_map[agent_type]
            if follow_up.get("is_follow_up"):
                response = self._create_follow_up_response(
                    question, agent_type, info, previous_conversations, follow_up
                )
            else:
                response = self._create_natural_ai_response(question, agent_type, info)

            # ëŒ€í™” ë¡œê·¸ ì—…ë°ì´íŠ¸
            current = {
                "timestamp": datetime.now().isoformat(),
                "question": question,
                "topic": self._extract_topic(question),
                "intent": follow_up.get("intent", "general"),
                "depth": follow_up.get("depth_level", 1),
            }
            self.conversation_history.setdefault(conversation_key, []).append(current)
            if len(self.conversation_history[conversation_key]) > 10:
                self.conversation_history[conversation_key] = self.conversation_history[
                    conversation_key
                ][-10:]
            self._save_conversation_history()

            if usage_tracker:
                usage_tracker.log_usage(agent_type, question, True, user_ip)

            return {
                "success": True,
                "agent": {
                    "type": agent_type,
                    "name": info["name"],
                    "emoji": info["emoji"],
                    "field": info["field"],
                },
                "response": response,
                "context": {
                    "previous_topics": previous_topics[-3:],
                    "intent": current["intent"],
                    "depth": current["depth"],
                },
            }
        except Exception as e:
            try:
                from usage_tracker import usage_tracker

                usage_tracker.log_usage(agent_type, question, False, user_ip)
            except Exception:
                pass
            return {"success": False, "error": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

    def _create_follow_up_response(
        self,
        question: str,
        agent_type: str,
        info: dict,
        previous_conversations: list,
        follow_up_analysis: dict,
    ) -> str:
        """í›„ì† ì§ˆë¬¸ ì‹¬í™” ì‘ë‹µ - ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì‚¬ìš©"""
        from response_context_manager import ResponseContextManager, ContextInfo

        previous_topics = [
            conv.get("topic", "") for conv in previous_conversations[-3:]
        ]
        depth = follow_up_analysis.get("depth_level", 2)
        intent = follow_up_analysis.get("intent", "general")

        # expertise_areas ë¹„ì–´ìˆì„ ê²½ìš° fieldë¥¼ ê¸°ë³¸ ì „ë¬¸ì˜ì—­ìœ¼ë¡œ ì‚¬ìš© (í•­ìƒ List[str])
        expertise_areas: list[str] = []
        raw_exp = info.get("expertise")
        if isinstance(raw_exp, list):
            expertise_areas = [str(x) for x in raw_exp if isinstance(x, str)]
        if not expertise_areas:
            expertise_areas = [str(info.get("field", "ì „ë¬¸"))]

        context_info = ContextInfo(
            current_time=datetime.now(),
            expertise_areas=expertise_areas,
            depth_level=depth,
            previous_topics=previous_topics,
            conversation_flow={"intent": [intent]},
        )

        manager = ResponseContextManager()
        return manager.create_expertise_based_response(question, info, context_info)

    def _extract_topic(self, question: str) -> str:
        """ì§ˆë¬¸ì—ì„œ ê°„ë‹¨í•œ í† í”½ ì¶”ì¶œ (ì„ í˜• ìŠ¬ë¼ì´ìŠ¤)"""
        q = (question or "").strip()
        return q[:30] if len(q) > 30 else q

    def _create_natural_ai_response(
        self, question: str, agent_type: str, info: dict
    ) -> str:
        """ì‹¤ì œ AIì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê³  ë§¥ë½ì ì¸ ì‘ë‹µ ìƒì„±"""

        # ë„ê¹¨ë¹„ë³„ ì „ë¬¸ ë¶„ì•¼ì™€ ì„±ê²© ì •ì˜
        agent_personalities = {
            "assistant": {
                "role": "íš¨ìœ¨ì ì´ê³  ì²´ê³„ì ì¸ ì—…ë¬´ ê´€ë¦¬ ì „ë¬¸ê°€",
                "style": "ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì¡°ì–¸",
                "expertise": ["ì‹œê°„ê´€ë¦¬", "ì—…ë¬´íš¨ìœ¨", "ìƒì‚°ì„±", "ê³„íšìˆ˜ë¦½", "ì¡°ì§ê´€ë¦¬"],
            },
            # ... (ë°±ì—… ìŠ¤ëƒ…ìƒ·)
        }

        personality = agent_personalities.get(
            agent_type,
            {"role": "ì „ë¬¸ê°€", "style": "ë„ì›€ì´ ë˜ëŠ” ì¡°ì–¸", "expertise": ["ì „ë¬¸ìƒë‹´"]},
        )

        # ì§ˆë¬¸ ë¶„ì„ ë° ë§¥ë½ì  ì‘ë‹µ ìƒì„±
        return self._generate_contextual_response(question, info, personality)

    def _generate_contextual_response(
        self, question: str, info: dict, personality: dict
    ) -> str:
        """ë§¥ë½ì„ ê³ ë ¤í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ ìƒì„±"""
        question_lower = question.lower()
        if any(
            expertise in question_lower for expertise in personality.get("expertise", [])
        ):
            return self._generate_expert_response(question, info, personality)
        return self._generate_general_expert_response(question, info, personality)

    def _generate_expert_response(
        self, question: str, info: dict, personality: dict
    ) -> str:
        from response_context_manager import ResponseContextManager, ContextInfo
        from datetime import datetime

        context_info = ContextInfo(
            current_time=datetime.now(),
            expertise_areas=personality.get("expertise", []),
            depth_level=1,
            previous_topics=[],
            conversation_flow={},
        )
        manager = ResponseContextManager()
        return manager.create_expertise_based_response(question, info, context_info)

    def _generate_general_expert_response(
        self, question: str, info: dict, personality: dict
    ) -> str:
        from response_context_manager import ResponseContextManager, ContextInfo
        from datetime import datetime

        context_info = ContextInfo(
            current_time=datetime.now(),
            expertise_areas=personality.get("expertise", []),
            depth_level=1,
            previous_topics=[],
            conversation_flow={},
        )
        manager = ResponseContextManager()
        return manager.create_expertise_based_response(question, info, context_info)

    def get_agent_info(self) -> Dict[str, Any]:
        agent_info = {
            "assistant": {"emoji": "ğŸ¤–", "name": "ë°•ì‚¬ê¸‰ ë¹„ì„œ ë„ê¹¨ë¹„", "field": "ì—…ë¬´ ê´€ë¦¬"},
            # ... (ë°±ì—… ìŠ¤ëƒ…ìƒ·)
        }
        return {
            "total_agents": len(agent_info),
            "agents": agent_info,
            "categories": {
                "ì—…ë¬´&ê´€ë¦¬": ["assistant", "hr", "village_chief", "growth"],
                # ... (ë°±ì—… ìŠ¤ëƒ…ìƒ·)
            },
        }


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
stem_ai = STEMIntegration()
