"""
ğŸ¯ AI ë„ê¹¨ë¹„ë§ˆì„ STEM ì„¼í„° - ì‹¤ì œ AI ëŒ€í™” ì‹œìŠ¤í…œ
ì§„ì§œ AIì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê³  ë§¥ë½ì ì¸ ì‘ë‹µì„ ì œê³µí•˜ëŠ” 16ê°œ ë„ê¹¨ë¹„ ì‹œìŠ¤í…œ
"""

import random
from datetime import datetime
from typing import Dict, Any, Optional
import hashlib
import json
import os
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel


class STEMIntegration:
    """STEM ë„ê¹¨ë¹„ë“¤ê³¼ì˜ ì‹¤ì œ AI ëŒ€í™” ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.system_name = "ğŸ° ë„ê¹¨ë¹„ë§ˆì„ì¥í„° ë°•ì‚¬ê¸‰ AI ìƒë‹´ì†Œ"
        # ëŒ€í™” ê¸°ë¡ ì €ì¥ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬ (ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ì €ì¥)
        self.conversation_history = {}
        self.context_file = "conversation_context.json"
        self._load_conversation_history()

    def _load_conversation_history(self):
        """ëŒ€í™” ê¸°ë¡ ë¡œë“œ"""
        try:
            if os.path.exists(self.context_file):
                with open(self.context_file, "r", encoding="utf-8") as f:
                    self.conversation_history = json.load(f)
        except Exception:
            self.conversation_history = {}

    def _save_conversation_history(self):
        """ëŒ€í™” ê¸°ë¡ ì €ì¥"""
        try:
            with open(self.context_file, "w", encoding="utf-8") as f:
                json.dump(self.conversation_history, f, ensure_ascii=False, indent=2)
        except Exception:
            pass

    def _get_conversation_key(self, user_ip: str, agent_type: str) -> str:
        """ì‚¬ìš©ì-ì—ì´ì „íŠ¸ë³„ ëŒ€í™” í‚¤ ìƒì„±"""
        key = f"{user_ip}_{agent_type}"
        return hashlib.md5(key.encode()).hexdigest()[:16]

    def _analyze_follow_up_intent(self, question: str, previous_topics: list) -> dict:
        """í›„ì† ì§ˆë¬¸ ì˜ë„ ë¶„ì„ - ê°„ë‹¨ ê·œì¹™ ê¸°ë°˜"""
        q = (question or "").strip().lower()

        indicators = {
            "more_detail": ["êµ¬ì²´ì ìœ¼ë¡œ", "ë” ìì„¸íˆ", "ì„¸ë¶€", "ìƒì„¸"],
            "example": ["ì˜ˆì‹œ", "ì‚¬ë¡€", "ì˜ˆë¥¼ ë“¤ì–´"],
            "how_to": ["ì–´ë–»ê²Œ", "ë°©ë²•", "ë‹¨ê³„", "ì ˆì°¨"],
            "advanced": ["ê³ ê¸‰", "ì‹¬í™”", "ì „ë¬¸", "ë” ê¹Šì´"],
            "practical": ["ì‹¤ë¬´", "í˜„ì‹¤ì ", "ë°”ë¡œ", "ì‹¤í–‰"],
        }

        intent = "general"
        for k, words in indicators.items():
            if any(w in q for w in words):
                intent = k
                break

        # ê°„ë‹¨í•œ follow-up ì‹ í˜¸
        follow_signals = [
            "ë‹¤ì‹œ",
            "ì´ì–´",
            "ì¶”ê°€",
            "ë”",
            "ê³„ì†",
            "ì•ì—ì„œ",
            "ë°©ê¸ˆ",
            "ìœ„ ë‚´ìš©",
        ]
        is_follow_up = False
        if previous_topics:
            recent_topics = [
                t.lower() for t in previous_topics[-3:] if isinstance(t, str)
            ]
            if any(sig in q for sig in follow_signals) or any(
                t and t in q for t in recent_topics
            ):
                is_follow_up = True

        depth_level = 1 + min(2, len(previous_topics)) if is_follow_up else 1

        return {
            "is_follow_up": is_follow_up,
            "intent": intent,
            "depth_level": depth_level,
        }

    def process_question(
        self, agent_type: str, question: str, user_ip: str
    ) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬ (ë™ì  ì‘ë‹µ)"""
        try:
            try:
                from usage_tracker import usage_tracker  # ì§€í‘œ ê¸°ë¡
            except Exception:
                usage_tracker = None

            info_map = self.get_agent_info().get("agents", {})
            if agent_type not in info_map:
                if usage_tracker:
                    usage_tracker.log_usage(agent_type, question, False, user_ip)
                return {
                    "success": False,
                    "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì—ì´ì „íŠ¸ íƒ€ì…: {agent_type}",
                }

            if not question or len(question.strip()) < 2:
                if usage_tracker:
                    usage_tracker.log_usage(agent_type, question, False, user_ip)
                return {
                    "success": False,
                    "error": "ì§ˆë¬¸ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìµœì†Œ 2ê¸€ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.",
                }

            conversation_key = self._get_conversation_key(user_ip, agent_type)
            previous_conversations = self.conversation_history.get(conversation_key, [])
            previous_topics = [c.get("topic", "") for c in previous_conversations]

            follow_up = self._analyze_follow_up_intent(question, previous_topics)

            info = info_map[agent_type].copy()  # ë³µì‚¬ë³¸ ìƒì„±
            info["type"] = agent_type  # agent_typeì„ infoì— ì¶”ê°€

            if follow_up.get("is_follow_up"):
                response = self._create_follow_up_response(
                    question, agent_type, info, previous_conversations, follow_up
                )
            else:
                response = self._create_natural_ai_response(question, agent_type, info)

            # ëŒ€í™” ë¡œê·¸ ì—…ë°ì´íŠ¸
            current = {
                "timestamp": datetime.now().isoformat(),
                "question": question,
                "topic": self._extract_topic(question),
                "intent": follow_up.get("intent", "general"),
                "depth": follow_up.get("depth_level", 1),
            }
            self.conversation_history.setdefault(conversation_key, []).append(current)
            if len(self.conversation_history[conversation_key]) > 10:
                self.conversation_history[conversation_key] = self.conversation_history[
                    conversation_key
                ][-10:]
            self._save_conversation_history()

            if usage_tracker:
                usage_tracker.log_usage(agent_type, question, True, user_ip)

            return {
                "success": True,
                "agent": {
                    "type": agent_type,
                    "name": info["name"],
                    "emoji": info["emoji"],
                    "field": info["field"],
                },
                "response": response,
                "context": {
                    "previous_topics": previous_topics[-3:],
                    "intent": current["intent"],
                    "depth": current["depth"],
                },
            }
        except Exception as e:
            try:
                from usage_tracker import usage_tracker

                usage_tracker.log_usage(agent_type, question, False, user_ip)
            except Exception:
                pass
            return {"success": False, "error": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

    def _create_follow_up_response(
        self,
        question: str,
        agent_type: str,
        info: dict,
        previous_conversations: list,
        follow_up_analysis: dict,
    ) -> str:
        """í›„ì† ì§ˆë¬¸ ì‹¬í™” ì‘ë‹µ - ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì‚¬ìš©"""
        from response_context_manager import ResponseContextManager, ContextInfo

        previous_topics = [
            conv.get("topic", "") for conv in previous_conversations[-3:]
        ]
        depth = follow_up_analysis.get("depth_level", 2)
        intent = follow_up_analysis.get("intent", "general")

        # expertise_areas ë¹„ì–´ìˆì„ ê²½ìš° fieldë¥¼ ê¸°ë³¸ ì „ë¬¸ì˜ì—­ìœ¼ë¡œ ì‚¬ìš© (í•­ìƒ List[str])
        expertise_areas: list[str] = []
        raw_exp = info.get("expertise")
        if isinstance(raw_exp, list):
            expertise_areas = [str(x) for x in raw_exp if isinstance(x, str)]
        if not expertise_areas:
            expertise_areas = [str(info.get("field", "ì „ë¬¸"))]

        context_info = ContextInfo(
            current_time=datetime.now(),
            expertise_areas=expertise_areas,
            depth_level=depth,
            previous_topics=previous_topics,
            conversation_flow={"intent": [intent]},
        )

        manager = ResponseContextManager()
        return manager.create_expertise_based_response(question, info, context_info)

    def _extract_topic(self, question: str) -> str:
        """ì§ˆë¬¸ì—ì„œ ê°„ë‹¨í•œ í† í”½ ì¶”ì¶œ (ì„ í˜• ìŠ¬ë¼ì´ìŠ¤)"""
        q = (question or "").strip()
        return q[:30] if len(q) > 30 else q

    def _create_natural_ai_response(
        self, question: str, agent_type: str, info: dict
    ) -> str:
        """ì‹¤ì œ AIì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê³  ë§¥ë½ì ì¸ ì‘ë‹µ ìƒì„±"""

        # ë„ê¹¨ë¹„ë³„ ì „ë¬¸ ë¶„ì•¼ì™€ ì„±ê²© ì •ì˜
        agent_personalities = {
            "assistant": {
                "role": "íš¨ìœ¨ì ì´ê³  ì²´ê³„ì ì¸ ì—…ë¬´ ê´€ë¦¬ ì „ë¬¸ê°€",
                "style": "ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì¡°ì–¸",
                "expertise": ["ì‹œê°„ê´€ë¦¬", "ì—…ë¬´íš¨ìœ¨", "ìƒì‚°ì„±", "ê³„íšìˆ˜ë¦½", "ì¡°ì§ê´€ë¦¬"],
            },
            "data_analyst": {
                "role": "ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì „ë¬¸ê°€",
                "style": "í†µê³„ì ì´ê³  ë…¼ë¦¬ì ì¸ ë¶„ì„",
                "expertise": ["ë°ì´í„°ë¶„ì„", "í†µê³„", "ë¨¸ì‹ ëŸ¬ë‹", "ë¹„ì¦ˆë‹ˆìŠ¤ì¸í…”ë¦¬ì „ìŠ¤"],
            },
            "creative": {
                "role": "ì°½ì˜ì  ì•„ì´ë””ì–´ ë° ë””ìì¸ ì „ë¬¸ê°€",
                "style": "í˜ì‹ ì ì´ê³  ì°½ì˜ì ì¸ ì œì•ˆ",
                "expertise": ["ë¸Œë ˆì¸ìŠ¤í† ë°", "ë””ìì¸ì”½í‚¹", "ì°½ì˜ì„±", "í˜ì‹ "],
            },
            "hr": {
                "role": "ì¸ì‚¬ ê´€ë¦¬ ë° ì¡°ì§ ë¬¸í™” ì „ë¬¸ê°€",
                "style": "ì¸ê°„ ì¤‘ì‹¬ì ì´ê³  ì²´ê³„ì ì¸ ì ‘ê·¼",
                "expertise": ["ì¸ì‚¬ê´€ë¦¬", "ì¡°ì§ë¬¸í™”", "ì±„ìš©", "êµìœ¡í›ˆë ¨"],
            },
            "marketing": {
                "role": "ë§ˆì¼€íŒ… ì „ëµ ë° ë¸Œëœë”© ì „ë¬¸ê°€",
                "style": "ì „ëµì ì´ê³  ì°½ì˜ì ì¸ ë§ˆì¼€íŒ…",
                "expertise": ["ë§ˆì¼€íŒ…ì „ëµ", "ë¸Œëœë”©", "ê³ ê°ë¶„ì„", "ìº í˜ì¸"],
            },
            "sales": {
                "role": "ì˜ì—… ì „ëµ ë° ê³ ê° ê´€ê³„ ì „ë¬¸ê°€",
                "style": "ì„¤ë“ë ¥ ìˆê³  ê³ ê° ì¤‘ì‹¬ì ",
                "expertise": ["ì˜ì—…ì „ëµ", "ê³ ê°ê´€ë¦¬", "í˜‘ìƒ", "ì„¸ì¼ì¦ˆ"],
            },
            "builder": {
                "role": "ì‹œìŠ¤í…œ ê°œë°œ ë° êµ¬ì¶• ì „ë¬¸ê°€",
                "style": "ê¸°ìˆ ì ì´ê³  ì‹¤ìš©ì ì¸ ì†”ë£¨ì…˜",
                "expertise": ["í”„ë¡œê·¸ë˜ë°", "ì‹œìŠ¤í…œì„¤ê³„", "ê°œë°œ", "ê¸°ìˆ ì»¨ì„¤íŒ…"],
            },
            "counselor": {
                "role": "ì‹¬ë¦¬ ìƒë‹´ ë° ë©˜íƒˆ ì¼€ì–´ ì „ë¬¸ê°€",
                "style": "ê³µê°ì ì´ê³  ì¹˜ìœ ì ì¸ ì ‘ê·¼",
                "expertise": ["ì‹¬ë¦¬ìƒë‹´", "ë©˜íƒˆí—¬ìŠ¤", "ì¹˜ë£Œ", "ì½”ì¹­"],
            },
            "fortune": {
                "role": "ìš´ì„¸ ë° ì ìˆ  ì „ë¬¸ê°€",
                "style": "ì‹ ë¹„ë¡­ê³  ì§ê´€ì ì¸ í•´ì„",
                "expertise": ["ìš´ì„¸", "íƒ€ë¡œ", "ëª…ë¦¬í•™", "ì ìˆ "],
            },
            "growth": {
                "role": "ì„±ì¥ ì „ëµ ë° ë°œì „ ì „ë¬¸ê°€",
                "style": "ë¯¸ë˜ ì§€í–¥ì ì´ê³  ì „ëµì ",
                "expertise": ["ì„±ì¥ì „ëµ", "ì‚¬ì—…í™•ì¥", "í˜ì‹ ", "ë°œì „ê³„íš"],
            },
            "seo": {
                "role": "SEO ë° ë””ì§€í„¸ ë§ˆì¼€íŒ… ì „ë¬¸ê°€",
                "style": "ë°ì´í„° ê¸°ë°˜ ìµœì í™”",
                "expertise": ["SEO", "ê²€ìƒ‰ì—”ì§„", "ë””ì§€í„¸ë§ˆì¼€íŒ…", "ì›¹ìµœì í™”"],
            },
            "shopping": {
                "role": "ì‡¼í•‘ëª° ë° ì»¤ë¨¸ìŠ¤ ì „ë¬¸ê°€",
                "style": "ê³ ê° ê²½í—˜ ì¤‘ì‹¬ì ",
                "expertise": ["ì´ì»¤ë¨¸ìŠ¤", "ì‡¼í•‘ëª°ìš´ì˜", "ì˜¨ë¼ì¸íŒë§¤", "ê³ ê°ê²½í—˜"],
            },
            "startup": {
                "role": "ìŠ¤íƒ€íŠ¸ì—… ì°½ì—… ë° ì‚¬ì—… ê¸°íš ì „ë¬¸ê°€",
                "style": "í˜ì‹ ì ì´ê³  ì‹¤í–‰ ì¤‘ì‹¬ì ",
                "expertise": ["ì°½ì—…", "ì‚¬ì—…ê³„íš", "íˆ¬ììœ ì¹˜", "ìŠ¤íƒ€íŠ¸ì—…"],
            },
            "medical": {
                "role": "ì˜ë£Œ ë° ê±´ê°• ê´€ë¦¬ ì „ë¬¸ê°€",
                "style": "ê³¼í•™ì ì´ê³  ì‹ ì¤‘í•œ ì¡°ì–¸",
                "expertise": ["ì˜ë£Œ", "ê±´ê°•ê´€ë¦¬", "ì˜ˆë°©ì˜í•™", "ì˜ë£Œìƒë‹´"],
            },
            "village_chief": {
                "role": "ë¦¬ë”ì‹­ ë° ì¡°ì§ ê´€ë¦¬ ì „ë¬¸ê°€",
                "style": "ë¦¬ë”ì‹­ ìˆê³  ì±…ì„ê° ìˆëŠ”",
                "expertise": ["ë¦¬ë”ì‹­", "ì¡°ì§ê´€ë¦¬", "ì˜ì‚¬ê²°ì •", "íŒ€ë¹Œë”©"],
            },
            "writing": {
                "role": "ê¸€ì“°ê¸° ë° ì½˜í…ì¸  ì œì‘ ì „ë¬¸ê°€",
                "style": "ì°½ì‘ì ì´ê³  í‘œí˜„ë ¥ í’ë¶€í•œ",
                "expertise": ["ê¸€ì“°ê¸°", "ì½˜í…ì¸ ì œì‘", "í¸ì§‘", "ìŠ¤í† ë¦¬í…”ë§"],
            },
        }

        personality = agent_personalities.get(
            agent_type,
            {"role": "ì „ë¬¸ê°€", "style": "ë„ì›€ì´ ë˜ëŠ” ì¡°ì–¸", "expertise": ["ì „ë¬¸ìƒë‹´"]},
        )

        # ì§ˆë¬¸ ë¶„ì„ ë° ë§¥ë½ì  ì‘ë‹µ ìƒì„±
        return self._generate_contextual_response(question, info, personality)

    def _generate_contextual_response(
        self, question: str, info: dict, personality: dict
    ) -> str:
        """ë§¥ë½ì„ ê³ ë ¤í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ ìƒì„±"""
        question_lower = question.lower()
        if any(
            expertise in question_lower
            for expertise in personality.get("expertise", [])
        ):
            return self._generate_expert_response(question, info, personality)
        return self._generate_general_expert_response(question, info, personality)

    def _generate_expert_response(
        self, question: str, info: dict, personality: dict
    ) -> str:
        """ì‹¤ì œ ë„ê¹¨ë¹„ íŒŒì¼ì„ í˜¸ì¶œí•˜ì—¬ ì „ë¬¸ ì‘ë‹µ ìƒì„± (ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ì—”ì§„ ì ìš©)"""
        try:
            # ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ì—”ì§„ ì„í¬íŠ¸
            from natural_conversation_engine import get_natural_response

            # ì—ì´ì „íŠ¸ íƒ€ì…ì— ë”°ë¼ ì‹¤ì œ ë„ê¹¨ë¹„ íŒŒì¼ í˜¸ì¶œ
            agent_type = info.get("type", "assistant")

            # ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ì—”ì§„ìœ¼ë¡œ ì‘ë‹µ ìƒì„±
            try:
                return get_natural_response(question, agent_type, info)
            except Exception as e:
                print(f"ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ì—”ì§„ ì‹¤íŒ¨: {e}")
                # ë°±ì—… ì‘ë‹µ ì‹œìŠ¤í…œ
                return self._generate_backup_friendly_response(
                    question, agent_type, info
                )

        except Exception as e:
            print(f"ë„ê¹¨ë¹„ í˜¸ì¶œ ì‹¤íŒ¨ ({agent_type}): {e}")
            return self._generate_backup_friendly_response(question, agent_type, info)

    def _generate_backup_friendly_response(
        self, question: str, agent_type: str, info: dict
    ) -> str:
        """ë°±ì—…ìš© ì¹œê·¼í•œ ì‘ë‹µ ìƒì„±"""
        agent_name = info.get("name", f"{agent_type} ë„ê¹¨ë¹„")
        agent_emoji = info.get("emoji", "ğŸ¤–")
        field = info.get("field", "ì „ë¬¸ ë¶„ì•¼")

        # ì¹œê·¼í•œ ì¸ì‚¬ë§
        friendly_greetings = [
            f"ì•ˆë…•í•˜ì„¸ìš”! {agent_emoji} {agent_name}ì´ì—ìš”! ğŸ˜Š",
            f"ë°˜ê°€ì›Œìš”! {agent_emoji} {agent_name}ì…ë‹ˆë‹¤! ğŸ¤—",
            f"ì–´ì„œì˜¤ì„¸ìš”! {agent_emoji} {agent_name}ì´ì—ìš”! âœ¨",
        ]

        greeting = random.choice(friendly_greetings)

        # ì§ˆë¬¸ì— ëŒ€í•œ ê³µê°ì  ë°˜ì‘
        empathy_responses = [
            "ì •ë§ ì¢‹ì€ ì§ˆë¬¸ì´ë„¤ìš”!",
            "í¥ë¯¸ë¡œìš´ ì£¼ì œë¥¼ ë§ì”€í•´ì£¼ì…¨ì–´ìš”!",
            "ì €ë„ ê·¸ëŸ° ê²ƒë“¤ì´ ì •ë§ ê¶ê¸ˆí•´ìš”!",
            "ì™€, ë©‹ì§„ ì§ˆë¬¸ì´ì—ìš”!",
        ]

        empathy = random.choice(empathy_responses)

        # ì „ë¬¸ì„± + ì¹œê·¼í•¨
        expertise_part = (
            f"{field} ì „ë¬¸ê°€ë¡œì„œ ë„ì›€ë“œë¦´ ìˆ˜ ìˆëŠ” ë¶€ë¶„ì´ ì •ë§ ë§ì„ ê²ƒ ê°™ì•„ìš”."
        )

        # ëŒ€í™” ìœ ë„
        conversation_starters = [
            "ì–´ë–¤ ë¶€ë¶„ì´ ê°€ì¥ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?",
            "êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ìƒí™©ì¸ì§€ ë” ë“¤ë ¤ì£¼ì„¸ìš”!",
            "ì–´ë–¤ ê²°ê³¼ë¥¼ ê¸°ëŒ€í•˜ê³  ê³„ì‹ ê°€ìš”?",
            "ì œê°€ ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?",
        ]

        starter = random.choice(conversation_starters)

        return (
            f"{greeting}\n\n{empathy} {expertise_part}\n\n{starter} í¸í•˜ê²Œ ëŒ€í™”í•´ìš”! ğŸ’«"
        )

    def _generate_general_expert_response(
        self, question: str, info: dict, personality: dict
    ) -> str:
        from response_context_manager import ResponseContextManager, ContextInfo
        from datetime import datetime

        context_info = ContextInfo(
            current_time=datetime.now(),
            expertise_areas=personality.get("expertise", []),
            depth_level=1,
            previous_topics=[],
            conversation_flow={},
        )
        manager = ResponseContextManager()
        return manager.create_expertise_based_response(question, info, context_info)

    def get_agent_info(self) -> Dict[str, Any]:
        agent_info = {
            "assistant": {
                "emoji": "ğŸ¤–",
                "name": "ë°•ì‚¬ê¸‰ ë¹„ì„œ ë„ê¹¨ë¹„",
                "field": "ì—…ë¬´ ê´€ë¦¬",
            },
            "data_analyst": {
                "emoji": "ğŸ“Š",
                "name": "ë°•ì‚¬ê¸‰ ë°ì´í„° ë¶„ì„ ë„ê¹¨ë¹„",
                "field": "ë¹…ë°ì´í„° ë¶„ì„",
            },
            "creative": {
                "emoji": "ğŸ¨",
                "name": "ë°•ì‚¬ê¸‰ ì°½ì˜ ë„ê¹¨ë¹„",
                "field": "ì°½ì˜ì  ì•„ì´ë””ì–´",
            },
            "hr": {
                "emoji": "ğŸ‘¥",
                "name": "ë°•ì‚¬ê¸‰ ì¸ì‚¬ ë„ê¹¨ë¹„",
                "field": "ì¸ì‚¬ ê´€ë¦¬",
            },
            "marketing": {
                "emoji": "ğŸ“ˆ",
                "name": "ë°•ì‚¬ê¸‰ ë§ˆì¼€íŒ… ë„ê¹¨ë¹„",
                "field": "ë§ˆì¼€íŒ… ì „ëµ",
            },
            "sales": {
                "emoji": "ğŸ’¼",
                "name": "ë°•ì‚¬ê¸‰ ì˜ì—… ë„ê¹¨ë¹„",
                "field": "ì˜ì—… ì „ëµ",
            },
            "builder": {
                "emoji": "ğŸ—ï¸",
                "name": "ë°•ì‚¬ê¸‰ ê°œë°œ ë„ê¹¨ë¹„",
                "field": "ì‹œìŠ¤í…œ ê°œë°œ",
            },
            "counselor": {
                "emoji": "ğŸ’",
                "name": "ë°•ì‚¬ê¸‰ ìƒë‹´ ë„ê¹¨ë¹„",
                "field": "ì‹¬ë¦¬ ìƒë‹´",
            },
            "fortune": {
                "emoji": "ğŸ”®",
                "name": "ë°•ì‚¬ê¸‰ ìš´ì„¸ ë„ê¹¨ë¹„",
                "field": "ìš´ì„¸ ì ìˆ ",
            },
            "growth": {
                "emoji": "ğŸ“ˆ",
                "name": "ë°•ì‚¬ê¸‰ ì„±ì¥ ë„ê¹¨ë¹„",
                "field": "ì„±ì¥ ì „ëµ",
            },
            "seo": {
                "emoji": "ğŸ”",
                "name": "ë°•ì‚¬ê¸‰ SEO ë„ê¹¨ë¹„",
                "field": "SEO ìµœì í™”",
            },
            "shopping": {
                "emoji": "ğŸ›’",
                "name": "ë°•ì‚¬ê¸‰ ì‡¼í•‘ ë„ê¹¨ë¹„",
                "field": "ì‡¼í•‘ëª° ìš´ì˜",
            },
            "startup": {
                "emoji": "ğŸš€",
                "name": "ë°•ì‚¬ê¸‰ ìŠ¤íƒ€íŠ¸ì—… ë„ê¹¨ë¹„",
                "field": "ì°½ì—… ì»¨ì„¤íŒ…",
            },
            "medical": {
                "emoji": "âš•ï¸",
                "name": "ë°•ì‚¬ê¸‰ ì˜ë£Œ ë„ê¹¨ë¹„",
                "field": "ì˜ë£Œ ìƒë‹´",
            },
            "village_chief": {
                "emoji": "ğŸ‘‘",
                "name": "ë°•ì‚¬ê¸‰ ì´Œì¥ ë„ê¹¨ë¹„",
                "field": "ë¦¬ë”ì‹­ ê´€ë¦¬",
            },
            "writing": {
                "emoji": "âœï¸",
                "name": "ë°•ì‚¬ê¸‰ ê¸€ì“°ê¸° ë„ê¹¨ë¹„",
                "field": "ì½˜í…ì¸  ì œì‘",
            },
        }
        return {
            "total_agents": len(agent_info),
            "agents": agent_info,
            "categories": {
                "ì—…ë¬´&ê´€ë¦¬": ["assistant", "hr", "village_chief", "growth"],
                "ë¹„ì¦ˆë‹ˆìŠ¤": ["marketing", "sales", "startup", "seo"],
                "ì°½ì‘&ê°œë°œ": ["creative", "builder", "writing", "shopping"],
                "ìƒë‹´&ì„œë¹„ìŠ¤": ["counselor", "fortune", "data_analyst", "medical"],
            },
        }


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
stem_ai = STEMIntegration()

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="ğŸ° ë„ê¹¨ë¹„ë§ˆì„ì¥í„° AI ìƒë‹´ì†Œ",
    description="16ê°œ ì „ë¬¸ ë„ê¹¨ë¹„ë“¤ì˜ ë°•ì‚¬ê¸‰ ìƒë‹´ ì„œë¹„ìŠ¤",
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì •ì  íŒŒì¼ ì„œë¹™ (CSS, JS, ì´ë¯¸ì§€ ë“±)
app.mount("/static", StaticFiles(directory="."), name="static")


# ìš”ì²­ ëª¨ë¸
class ChatRequest(BaseModel):
    message: str
    agent_type: str


class ChatResponse(BaseModel):
    response: str
    agent_name: str
    agent_emoji: str


@app.get("/")
async def root():
    """í™ˆí˜ì´ì§€"""
    return FileResponse("index.html")


@app.get("/index.html")
async def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return FileResponse("index.html")


@app.get("/agents")
async def get_agents():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ëª©ë¡ ì¡°íšŒ"""
    return stem_ai.get_agent_info()


@app.post("/chat", response_model=ChatResponse)
async def chat_with_agent(request: ChatRequest):
    """ë„ê¹¨ë¹„ì™€ ëŒ€í™”í•˜ê¸°"""
    try:
        # ë„ê¹¨ë¹„ì™€ ëŒ€í™” (ì„ì‹œ IP ì‚¬ìš©)
        result = stem_ai.process_question(
            agent_type=request.agent_type, question=request.message, user_ip="127.0.0.1"
        )

        # ì—ì´ì „íŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        agent_info = stem_ai.get_agent_info()
        agent_data = agent_info["agents"].get(request.agent_type, {})

        return ChatResponse(
            response=result.get("response", "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."),
            agent_name=agent_data.get("name", f"{request.agent_type} ë„ê¹¨ë¹„"),
            agent_emoji=agent_data.get("emoji", "ğŸ¤–"),
        )
    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"ë„ê¹¨ë¹„ì™€ ëŒ€í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8001)
