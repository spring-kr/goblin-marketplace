"""
ğŸ¯ ì‚¬ìš©ì ë§ì¶¤í˜• ê°ì •ë¶„ì„ ëª¨ë¸ ë¡œë”
ì‚¬ìš©ìê°€ ì§ì ‘ í•™ìŠµì‹œí‚¨ ëª¨ë¸ íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ê°ì •ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ì‹œìŠ¤í…œ
"""

import os
import pickle
import joblib
import json
import numpy as np
import torch
from typing import Dict, List, Tuple, Optional, Any
import warnings

warnings.filterwarnings("ignore")


class CustomEmotionModelLoader:
    """ì‚¬ìš©ì ë§ì¶¤í˜• ê°ì •ë¶„ì„ ëª¨ë¸ ë¡œë”"""

    def __init__(self, model_path: Optional[str] = None):
        self.model = None
        self.tokenizer = None
        self.vectorizer = None
        self.label_encoder = None
        self.model_type = None
        self.is_loaded = False
        self.config = None

        if model_path and os.path.exists(model_path):
            self.load_model(model_path)

    def load_model(self, model_path: str) -> bool:
        """ë‹¤ì–‘í•œ í˜•íƒœì˜ ëª¨ë¸ íŒŒì¼ ë¡œë“œ"""
        try:
            print(f"ğŸ”„ ëª¨ë¸ ë¡œë“œ ì‹œë„: {model_path}")

            # íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ ë¡œë“œ ë°©ì‹ ê²°ì •
            file_ext = os.path.splitext(model_path)[1].lower()

            if file_ext == ".pkl":
                return self._load_pickle_model(model_path)
            elif file_ext == ".joblib":
                return self._load_joblib_model(model_path)
            elif file_ext == ".json":
                return self._load_json_config(model_path)
            elif os.path.isdir(model_path):
                return self._load_model_directory(model_path)
            else:
                print(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}")
                return False

        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def _load_pickle_model(self, model_path: str) -> bool:
        """Pickle íŒŒì¼ ë¡œë“œ (PyTorch ëª¨ë¸ í¬í•¨)"""
        try:
            with open(model_path, "rb") as f:
                model_data = pickle.load(f)

            # PyTorch ëª¨ë¸ì¸ì§€ í™•ì¸
            if hasattr(model_data, 'state_dict') or isinstance(model_data, torch.nn.Module):
                self.model = model_data
                self.model_type = "pytorch"
                # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
                if hasattr(self.model, 'eval'):
                    self.model.eval()
                print("âœ… PyTorch ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
            # ë‹¨ì¼ ëª¨ë¸ì¸ì§€ ì—¬ëŸ¬ ì»´í¬ë„ŒíŠ¸ê°€ í¬í•¨ëœ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸
            elif isinstance(model_data, dict):
                # PyTorch ëª¨ë¸ì´ ë”•ì…”ë„ˆë¦¬ì— í¬í•¨ëœ ê²½ìš°
                if 'model' in model_data and hasattr(model_data['model'], 'state_dict'):
                    self.model = model_data.get("model")
                    self.tokenizer = model_data.get("tokenizer")
                    self.config = model_data.get("config")
                    self.model_type = "pytorch"
                    if hasattr(self.model, 'eval'):
                        self.model.eval()
                    print("âœ… PyTorch ëª¨ë¸ (ë”•ì…”ë„ˆë¦¬) ë¡œë“œ ì„±ê³µ!")
                else:
                    self.model = model_data.get("model")
                    self.vectorizer = model_data.get("vectorizer")
                    self.label_encoder = model_data.get("label_encoder")
                    self.model_type = model_data.get("model_type", "custom")
                    print("âœ… ì»¤ìŠ¤í…€ ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
            else:
                self.model = model_data
                self.model_type = "sklearn"
                print("âœ… Scikit-learn ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")

            self.is_loaded = True
            return True

        except Exception as e:
            print(f"âŒ Pickle ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def _load_joblib_model(self, model_path: str) -> bool:
        """Joblib íŒŒì¼ ë¡œë“œ (íŒŒì´í”„ë¼ì¸ í¬í•¨)"""
        try:
            model_data = joblib.load(model_path)

            # Pipeline ê°ì²´ì¸ì§€ í™•ì¸
            if hasattr(model_data, 'named_steps'):
                # Scikit-learn Pipeline
                self.model = model_data
                self.model_type = "pipeline"
                print("âœ… Scikit-learn íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì„±ê³µ!")
            elif isinstance(model_data, dict):
                self.model = model_data.get("model")
                self.vectorizer = model_data.get("vectorizer")
                self.label_encoder = model_data.get("label_encoder")
                self.model_type = model_data.get("model_type", "custom")
                print("âœ… ë”•ì…”ë„ˆë¦¬ ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
            else:
                self.model = model_data
                self.model_type = "sklearn"
                print("âœ… Scikit-learn ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")

            self.is_loaded = True
            return True

        except Exception as e:
            print(f"âŒ Joblib ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def _load_json_config(self, config_path: str) -> bool:
        """JSON ì„¤ì • íŒŒì¼ì—ì„œ ëª¨ë¸ ê²½ë¡œ ì •ë³´ ë¡œë“œ"""
        try:
            with open(config_path, "r", encoding="utf-8") as f:
                config = json.load(f)

            model_file = config.get("model_path")
            vectorizer_file = config.get("vectorizer_path")

            if model_file and os.path.exists(model_file):
                if model_file.endswith(".pkl"):
                    with open(model_file, "rb") as f:
                        self.model = pickle.load(f)
                elif model_file.endswith(".joblib"):
                    self.model = joblib.load(model_file)

            if vectorizer_file and os.path.exists(vectorizer_file):
                if vectorizer_file.endswith(".pkl"):
                    with open(vectorizer_file, "rb") as f:
                        self.vectorizer = pickle.load(f)
                elif vectorizer_file.endswith(".joblib"):
                    self.vectorizer = joblib.load(vectorizer_file)

            self.model_type = config.get("model_type", "custom")
            self.is_loaded = True
            print("âœ… JSON ì„¤ì • ê¸°ë°˜ ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
            return True

        except Exception as e:
            print(f"âŒ JSON ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def _load_model_directory(self, model_dir: str) -> bool:
        """ëª¨ë¸ ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ë“¤ ìë™ íƒì§€ í›„ ë¡œë“œ"""
        try:
            # ì¼ë°˜ì ì¸ ëª¨ë¸ íŒŒì¼ëª… íŒ¨í„´ë“¤
            model_patterns = [
                "model.pkl",
                "model.joblib", 
                "emotion_model.pkl",
                "emotion_model.joblib",
                "classifier.pkl",
                "classifier.joblib",
                "korean_bert_emotion.pkl",  # ì¶”ê°€ëœ íŒ¨í„´
                "*emotion*.pkl",  # ê°ì • ê´€ë ¨ íŒ¨í„´
                "*bert*.pkl",     # BERT ê´€ë ¨ íŒ¨í„´
            ]

            vectorizer_patterns = [
                "vectorizer.pkl",
                "vectorizer.joblib",
                "tfidf.pkl",
                "tfidf.joblib",
                "count_vectorizer.pkl",
                "count_vectorizer.joblib",
            ]

            # ì‹¤ì œ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  .pkl íŒŒì¼ ê²€ìƒ‰
            import glob
            pkl_files = glob.glob(os.path.join(model_dir, "*.pkl"))
            pth_files = glob.glob(os.path.join(model_dir, "*.pth"))  # PyTorch ëª¨ë¸
            
            print(f"ğŸ” ë°œê²¬ëœ ëª¨ë¸ íŒŒì¼ë“¤: {pkl_files + pth_files}")

            # ëª¨ë¸ íŒŒì¼ ì°¾ê¸° - ì§ì ‘ ê²€ìƒ‰
            for pkl_file in pkl_files:
                file_name = os.path.basename(pkl_file).lower()
                if any(keyword in file_name for keyword in ["emotion", "bert", "model", "classifier"]):
                    print(f"ğŸ¯ ëª¨ë¸ íŒŒì¼ ë¡œë“œ ì‹œë„: {pkl_file}")
                    try:
                        if pkl_file.endswith(".pkl"):
                            with open(pkl_file, "rb") as f:
                                model_data = pickle.load(f)
                            
                            # PyTorch ëª¨ë¸ì¸ì§€ í™•ì¸
                            if hasattr(model_data, 'state_dict') or isinstance(model_data, torch.nn.Module):
                                self.model = model_data
                                self.model_type = "pytorch"
                                print(f"âœ… PyTorch ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {pkl_file}")
                            elif isinstance(model_data, dict):
                                self.model = model_data.get("model")
                                self.tokenizer = model_data.get("tokenizer")
                                self.config = model_data.get("config")
                                self.model_type = "pytorch" if hasattr(self.model, 'state_dict') else "sklearn"
                                print(f"âœ… ë”•ì…”ë„ˆë¦¬ ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {pkl_file}")
                            else:
                                self.model = model_data
                                self.model_type = "sklearn"
                                print(f"âœ… Scikit-learn ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {pkl_file}")
                            break
                    except Exception as e:
                        print(f"âš ï¸ {pkl_file} ë¡œë“œ ì‹¤íŒ¨: {e}")
                        continue

            # ë²¡í„°ë¼ì´ì € íŒŒì¼ ì°¾ê¸°
            for pattern in vectorizer_patterns:
                vec_path = os.path.join(model_dir, pattern)
                if os.path.exists(vec_path):
                    if pattern.endswith(".pkl"):
                        with open(vec_path, "rb") as f:
                            self.vectorizer = pickle.load(f)
                    else:
                        self.vectorizer = joblib.load(vec_path)
                    break

            if self.model:
                self.is_loaded = True
                print("âœ… ëª¨ë¸ ë””ë ‰í† ë¦¬ ë¡œë“œ ì„±ê³µ!")
                return True
            else:
                print("âŒ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False

        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë””ë ‰í† ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def predict_emotion(self, text: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ëª¨ë¸ë¡œ ê°ì • ì˜ˆì¸¡"""
        if not self.is_loaded or not self.model:
            return self._fallback_emotion_analysis(text)

        try:
            # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
            processed_text = self._preprocess_text(text)

            # PyTorch ëª¨ë¸ ì²˜ë¦¬
            if self.model_type == "pytorch":
                return self._predict_with_pytorch(processed_text)
            
            # Pipeline ëª¨ë¸ ì²˜ë¦¬
            elif self.model_type == "pipeline":
                return self._predict_with_pipeline(processed_text)
            
            # ë²¡í„°í™” (vectorizerê°€ ìˆëŠ” ê²½ìš°ë§Œ ì²˜ë¦¬)
            if self.vectorizer:
                try:
                    text_vector = self.vectorizer.transform([processed_text])
                except Exception as e:
                    print(f"âš ï¸ ë²¡í„°í™” ì‹¤íŒ¨: {e}")
                    return self._fallback_emotion_analysis(processed_text)
            else:
                # ë²¡í„°ë¼ì´ì €ê°€ ì—†ìœ¼ë©´ ëª¨ë¸ ì‚¬ìš© ë¶ˆê°€, í´ë°± ì‚¬ìš©
                print("âš ï¸ ë²¡í„°ë¼ì´ì € ì—†ìŒ, í´ë°± ë¶„ì„ ì‚¬ìš©")
                return self._fallback_emotion_analysis(processed_text)

            # ì˜ˆì¸¡ ìˆ˜í–‰ (ë²¡í„°ë¼ì´ì €ê°€ ìˆëŠ” ê²½ìš°ë§Œ)
            if hasattr(self.model, "predict_proba") and self.model_type != "pytorch":
                # í™•ë¥  ì˜ˆì¸¡ì´ ê°€ëŠ¥í•œ scikit-learn ëª¨ë¸
                try:
                    probabilities = self.model.predict_proba(text_vector)[0]
                    prediction = self.model.predict(text_vector)[0]

                    # í´ë˜ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
                    if hasattr(self.model, "classes_"):
                        classes = self.model.classes_
                    else:
                        classes = [f"ê°ì •_{i}" for i in range(len(probabilities))]

                    # ê²°ê³¼ êµ¬ì„±
                    emotion_scores = dict(zip(classes, probabilities))
                    primary_emotion = str(prediction)
                    confidence = float(max(probabilities))
                except Exception as e:
                    print(f"âš ï¸ Scikit-learn ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                    return self._fallback_emotion_analysis(processed_text)

            else:
                # ë‹¨ìˆœ ì˜ˆì¸¡ë§Œ ê°€ëŠ¥í•œ ëª¨ë¸
                try:
                    prediction = self.model.predict(text_vector)[0]
                    primary_emotion = str(prediction)
                    confidence = 0.8  # ê¸°ë³¸ê°’
                    emotion_scores = {primary_emotion: confidence}
                except Exception as e:
                    print(f"âš ï¸ ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                    return self._fallback_emotion_analysis(processed_text)

            # ê°•ë„ ê³„ì‚°
            intensity = (
                "ë†’ìŒ" if confidence > 0.7 else "ë³´í†µ" if confidence > 0.4 else "ë‚®ìŒ"
            )

            return {
                "primary_emotion": primary_emotion,
                "confidence": confidence,
                "intensity": intensity,
                "all_emotions": emotion_scores,
                "analysis_method": f"Custom_{self.model_type}",
                "model_info": {
                    "type": self.model_type,
                    "has_vectorizer": self.vectorizer is not None,
                    "model_class": type(self.model).__name__,
                },
            }

        except Exception as e:
            print(f"âŒ ì‚¬ìš©ì ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return self._fallback_emotion_analysis(text)

    def _predict_with_pytorch(self, text: str) -> Dict[str, Any]:
        """PyTorch ëª¨ë¸ë¡œ ê°ì • ì˜ˆì¸¡"""
        try:
            # ê¸°ë³¸ ê°ì • í´ë˜ìŠ¤ (configì—ì„œ ë¡œë“œí•˜ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©)
            emotion_classes = [
                "ë¶ˆì•ˆ", "ìš°ìš¸", "ë¶„ë…¸", "ë‘ë ¤ì›€", "ìŠ¬í””",
                "ê¸°ì¨", "ì•ˆë„", "í¬ë§", "ê°ì‚¬", "ì¤‘ë¦½"
            ]
            
            if self.config and "emotion_categories" in self.config:
                emotion_classes = self.config["emotion_categories"]["class_labels"]

            # ê°„ë‹¨í•œ í† í°í™” (ì‹¤ì œë¡œëŠ” tokenizer ì‚¬ìš©)
            if self.tokenizer:
                # BERT í† í¬ë‚˜ì´ì € ì‚¬ìš©
                inputs = self.tokenizer(
                    text, 
                    max_length=512, 
                    padding='max_length', 
                    truncation=True, 
                    return_tensors='pt'
                )
                
                # ëª¨ë¸ ì˜ˆì¸¡
                with torch.no_grad():
                    outputs = self.model(**inputs)
                    if hasattr(outputs, 'logits'):
                        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
                    else:
                        predictions = torch.nn.functional.softmax(outputs, dim=-1)
                
                # ê²°ê³¼ ì²˜ë¦¬
                probabilities = predictions[0].cpu().numpy()
                emotion_scores = dict(zip(emotion_classes, probabilities))
                
                # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ ê°ì • ì°¾ê¸°
                max_idx = int(torch.argmax(predictions[0]).item())
                primary_emotion = emotion_classes[max_idx] if max_idx < len(emotion_classes) else "ì¤‘ë¦½"
                confidence = float(probabilities[max_idx])
                
                # ê°•ë„ ê³„ì‚°
                intensity = (
                    "ë†’ìŒ" if confidence > 0.7 else "ë³´í†µ" if confidence > 0.4 else "ë‚®ìŒ"
                )
                
                return {
                    "primary_emotion": primary_emotion,
                    "confidence": confidence,
                    "intensity": intensity, 
                    "all_emotions": emotion_scores,
                    "analysis_method": "Custom_PyTorch_BERT",
                    "model_info": {
                        "type": "pytorch_bert",
                        "has_tokenizer": True,
                        "model_class": type(self.model).__name__,
                    },
                }
                
            else:
                # í† í¬ë‚˜ì´ì €ê°€ ì—†ëŠ” ê²½ìš° í´ë°±
                return self._fallback_emotion_analysis(text)

        except Exception as e:
            print(f"âŒ PyTorch ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return self._fallback_emotion_analysis(text)

    def _predict_with_pipeline(self, text: str) -> Dict[str, Any]:
        """Scikit-learn íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ê°ì • ì˜ˆì¸¡"""
        try:
            # íŒŒì´í”„ë¼ì¸ ì§ì ‘ ì‚¬ìš© (ë²¡í„°í™” + ì˜ˆì¸¡ í†µí•©)
            prediction = self.model.predict([text])[0]
            
            # í™•ë¥  ì˜ˆì¸¡ (ê°€ëŠ¥í•œ ê²½ìš°)
            if hasattr(self.model, 'predict_proba'):
                probabilities = self.model.predict_proba([text])[0]
                
                # í´ë˜ìŠ¤ ë¼ë²¨ ê°€ì ¸ì˜¤ê¸°
                if hasattr(self.model, 'classes_'):
                    classes = self.model.classes_
                else:
                    # íŒŒì´í”„ë¼ì¸ì˜ ë¶„ë¥˜ê¸°ì—ì„œ í´ë˜ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                    classifier = self.model.named_steps.get('classifier')
                    if hasattr(classifier, 'classes_'):
                        classes = classifier.classes_
                    else:
                        classes = ["ê¸°ì¨", "ìŠ¬í””", "ë¶„ë…¸", "ë¶ˆì•ˆ", "ì¤‘ë¦½"]
                
                emotion_scores = dict(zip(classes, probabilities))
                confidence = float(max(probabilities))
            else:
                # í™•ë¥  ì˜ˆì¸¡ì´ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°
                emotion_scores = {str(prediction): 0.8}
                confidence = 0.8
            
            # ê°•ë„ ê³„ì‚°
            intensity = (
                "ë†’ìŒ" if confidence > 0.7 else "ë³´í†µ" if confidence > 0.4 else "ë‚®ìŒ"
            )
            
            return {
                "primary_emotion": str(prediction),
                "confidence": confidence,
                "intensity": intensity,
                "all_emotions": emotion_scores,
                "analysis_method": "Scikit_Learn_Pipeline",
                "model_info": {
                    "type": "pipeline",
                    "has_vectorizer": True,
                    "model_class": type(self.model).__name__,
                },
            }

        except Exception as e:
            print(f"âŒ íŒŒì´í”„ë¼ì¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return self._fallback_emotion_analysis(text)

    def _preprocess_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        # ê¸°ë³¸ì ì¸ ì „ì²˜ë¦¬ (ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ìˆ˜ì • ê°€ëŠ¥)
        import re

        # ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
        text = re.sub(r"[^\w\sê°€-í£]", "", text)
        # ê³µë°± ì •ë¦¬
        text = " ".join(text.split())
        # ì†Œë¬¸ì ë³€í™˜ (í•œê¸€ì€ í•´ë‹¹ ì—†ìŒ)

        return text

    def _fallback_emotion_analysis(self, text: str) -> Dict[str, Any]:
        """ë°±ì—…ìš© ê·œì¹™ ê¸°ë°˜ ê°ì •ë¶„ì„"""
        emotion_keywords = {
            "ê¸°ì¨": ["ê¸°ì˜", "í–‰ë³µ", "ì¢‹ì•„", "ì¦ê±°", "ì›ƒìŒ", "ì‹ ë‚˜"],
            "ìŠ¬í””": ["ìŠ¬í”„", "ìš°ìš¸", "í˜ë“¤", "ì•„í”„", "ëˆˆë¬¼"],
            "ë¶„ë…¸": ["í™”ë‚˜", "ì§œì¦", "ë¶„ë…¸", "ì—´ë°›"],
            "ë¶ˆì•ˆ": ["ê±±ì •", "ë¶ˆì•ˆ", "ë¬´ì„œ", "ë‘ë ¤"],
            "ì¤‘ë¦½": ["ê·¸ëƒ¥", "ë³´í†µ", "í‰ë²”"],
        }

        text_lower = text.lower()
        emotion_scores = {}

        for emotion, keywords in emotion_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text_lower)
            emotion_scores[emotion] = score / len(keywords)  # ì •ê·œí™”

        primary_emotion = max(emotion_scores.keys(), key=lambda k: emotion_scores[k])
        confidence = emotion_scores[primary_emotion]

        return {
            "primary_emotion": primary_emotion,
            "confidence": confidence,
            "intensity": "ë³´í†µ",
            "all_emotions": emotion_scores,
            "analysis_method": "Fallback_Rule_Based",
        }

    def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            "is_loaded": self.is_loaded,
            "model_type": self.model_type,
            "has_model": self.model is not None,
            "has_vectorizer": self.vectorizer is not None,
            "model_class": type(self.model).__name__ if self.model else None,
        }


# ì‚¬ìš©ì ëª¨ë¸ ê²½ë¡œ ì„¤ì • (ì—¬ëŸ¬ ê°€ëŠ¥ì„± ì‹œë„)
def find_user_model() -> Optional[str]:
    """ì‚¬ìš©ì ëª¨ë¸ íŒŒì¼ ìë™ íƒì§€"""
    possible_paths = [
        "./emotion_model.pkl",
        "./emotion_model.joblib",
        "./model.pkl",
        "./model.joblib",
        "./models/",
        "../models/",
        "./my_emotion_model.pkl",
        "./korean_emotion_model.pkl",
    ]

    for path in possible_paths:
        if os.path.exists(path):
            print(f"ğŸ” ì‚¬ìš©ì ëª¨ë¸ ë°œê²¬: {path}")
            return path

    return None


# ì „ì—­ ì‚¬ìš©ì ëª¨ë¸ ë¡œë”
user_model_path = find_user_model()
custom_emotion_loader = CustomEmotionModelLoader(user_model_path)


def analyze_emotion_with_user_model(text: str) -> Dict[str, Any]:
    """ì‚¬ìš©ì ëª¨ë¸ì„ ì‚¬ìš©í•œ ê°ì •ë¶„ì„ (ì™¸ë¶€ í˜¸ì¶œìš©)"""
    return custom_emotion_loader.predict_emotion(text)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    print("ğŸ¯ ì‚¬ìš©ì ë§ì¶¤í˜• ê°ì •ë¶„ì„ ëª¨ë¸ í…ŒìŠ¤íŠ¸\n")

    # ëª¨ë¸ ì •ë³´ ì¶œë ¥
    info = custom_emotion_loader.get_model_info()
    print("ëª¨ë¸ ì •ë³´:")
    for key, value in info.items():
        print(f"  {key}: {value}")
    print()

    # í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤
    test_texts = [
        "ì˜¤ëŠ˜ ì •ë§ ê¸°ë¶„ì´ ì¢‹ì•„ìš”!",
        "ë„ˆë¬´ ìŠ¬í”„ê³  ìš°ìš¸í•´ìš”...",
        "ì •ë§ í™”ê°€ ë‚˜ìš”!",
        "ê±±ì •ì´ ë§ì•„ì„œ ì ì„ ëª» ìê² ì–´ìš”",
        "ê·¸ëƒ¥ í‰ë²”í•œ í•˜ë£¨ì˜€ì–´ìš”",
    ]

    for text in test_texts:
        result = analyze_emotion_with_user_model(text)
        print(f"ì…ë ¥: {text}")
        print(f"ê°ì •: {result['primary_emotion']} (í™•ì‹ ë„: {result['confidence']:.2f})")
        print(f"ë°©ë²•: {result['analysis_method']}")
        print("-" * 50)
