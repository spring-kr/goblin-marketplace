"""
ğŸ§  ëŒ€í™” ê¸°ì–µ/í•™ìŠµ ì‹œìŠ¤í…œ v11.0 - ì‹¤ì‹œê°„ í•™ìŠµ & 32ëª… ì „ë¬¸ê°€ ì§€ì›
=================================================================

v10.1 â†’ v11.0 ì£¼ìš” ì—…ê·¸ë ˆì´ë“œ:
1. ì „ë¬¸ê°€ 16ëª… â†’ 32ëª… í™•ì¥
2. ì‹¤ì‹œê°„ í”¼ë“œë°± í•™ìŠµ ì‹œìŠ¤í…œ
3. ìƒí™©ë³„ ë§ì¶¤ ì‘ë‹µ ì—”ì§„
4. ì—°ì† ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
5. ëŒ€í™” íŒ¨í„´ ë¶„ì„ AI
"""

import json
import os
import time
import asyncio
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from enum import Enum
import threading
import sqlite3
from pathlib import Path


class ConversationMode(Enum):
    """ëŒ€í™” ëª¨ë“œ ì •ì˜"""

    SINGLE = "ë‹¨ì¼ ì§ˆë¬¸"
    CONTINUOUS = "ì—°ì† ëŒ€í™”"
    DEEP_DIVE = "ì‹¬í™” íƒêµ¬"
    PROBLEM_SOLVING = "ë¬¸ì œ í•´ê²°"
    CREATIVE = "ì°½ì˜ì  í˜‘ì—…"


class FeedbackType(Enum):
    """í”¼ë“œë°± ìœ í˜•"""

    POSITIVE = "ì¢‹ìŒ"
    NEGATIVE = "ë‚˜ì¨"
    HELPFUL = "ë„ì›€ë¨"
    IRRELEVANT = "ê´€ë ¨ì—†ìŒ"
    MORE_DETAIL = "ë” ìì„¸íˆ"
    SIMPLER = "ë” ê°„ë‹¨íˆ"


@dataclass
class ConversationContext:
    """ì—°ì† ëŒ€í™” ì»¨í…ìŠ¤íŠ¸"""

    conversation_id: str
    mode: ConversationMode
    topic: str
    expert_chain: List[str]  # ì°¸ì—¬í•œ ì „ë¬¸ê°€ë“¤
    context_history: List[Dict]
    current_goal: str
    progress: float  # 0.0 ~ 1.0
    last_updated: float


@dataclass
class UserFeedback:
    """ì‚¬ìš©ì í”¼ë“œë°± ë°ì´í„°"""

    conversation_id: str
    message_id: str
    feedback_type: FeedbackType
    rating: int  # 1-5
    comment: Optional[str]
    timestamp: float


class AdvancedMemorySystem:
    """ê³ ê¸‰ ë©”ëª¨ë¦¬ ë° í•™ìŠµ ì‹œìŠ¤í…œ v11.0"""

    def __init__(self, memory_file: str = "advanced_memory_v11.json"):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.memory_file = memory_file
        self.db_file = memory_file.replace(".json", ".db")

        # ê¸°ë³¸ ë°ì´í„° êµ¬ì¡°
        self.conversation_history: List[Dict[str, Any]] = []
        self.user_preferences: Dict[str, Any] = {}
        self.feedback_history: List[UserFeedback] = []
        self.context_sessions: Dict[str, ConversationContext] = {}

        # ì‹¤ì‹œê°„ í•™ìŠµ ë°ì´í„°
        self.pattern_learning: Dict[str, Any] = {}
        self.expert_performance: Dict[str, Dict] = {}
        self.adaptation_rules: List[Dict] = []

        # 32ëª… ì „ë¬¸ê°€ ì‹œìŠ¤í…œ
        self.experts = self._initialize_32_experts()

        # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        self._init_database()
        self.load_memory()

        print(f"ğŸ§  AdvancedMemorySystem v11.0 ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ğŸ“Š 32ëª… ì „ë¬¸ê°€ ì‹œìŠ¤í…œ í™œì„±í™”")
        print(f"ğŸ”„ ì‹¤ì‹œê°„ í•™ìŠµ ëª¨ë“œ ON")

    def _initialize_32_experts(self) -> Dict[str, Dict]:
        """32ëª… ì „ë¬¸ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        experts = {
            # ê¸°ì¡´ 16ëª… (ê°œì„ )
            "counselor": {"name": "ğŸ’š ìƒë‹´ì‚¬", "field": "ì‹¬ë¦¬ìƒë‹´", "level": "ë°•ì‚¬ê¸‰"},
            "marketing": {
                "name": "ğŸ“ˆ ë§ˆì¼€í„°",
                "field": "ë§ˆì¼€íŒ…ì „ëµ",
                "level": "ë°•ì‚¬ê¸‰",
            },
            "finance": {"name": "ğŸ’° ê¸ˆìœµì‚¬", "field": "ê¸ˆìœµíˆ¬ì", "level": "ë°•ì‚¬ê¸‰"},
            "medical": {"name": "ğŸ‘¨â€âš•ï¸ ì˜ì‚¬", "field": "ì˜ë£Œì§„ë‹¨", "level": "ë°•ì‚¬ê¸‰"},
            "education": {
                "name": "ğŸ‘©â€ğŸ« êµìœ¡ì",
                "field": "êµìœ¡ì„¤ê³„",
                "level": "ë°•ì‚¬ê¸‰",
            },
            "creative": {"name": "ğŸ¨ ì°½ì‘ì", "field": "ì˜ˆìˆ ì°½ì‘", "level": "ë°•ì‚¬ê¸‰"},
            "tech": {"name": "ğŸ’» ê°œë°œì", "field": "ê¸°ìˆ ê°œë°œ", "level": "ë°•ì‚¬ê¸‰"},
            "business": {"name": "ğŸ¢ ê²½ì˜ì", "field": "ê²½ì˜ì „ëµ", "level": "ë°•ì‚¬ê¸‰"},
            "legal": {"name": "âš–ï¸ ë³€í˜¸ì‚¬", "field": "ë²•ë¥ ìƒë‹´", "level": "ë°•ì‚¬ê¸‰"},
            "environment": {
                "name": "ğŸŒ± í™˜ê²½í•™ì",
                "field": "í™˜ê²½ë³´í˜¸",
                "level": "ë°•ì‚¬ê¸‰",
            },
            "music": {"name": "ğŸµ ìŒì•…ê°€", "field": "ìŒì•…ì°½ì‘", "level": "ë°•ì‚¬ê¸‰"},
            "literature": {"name": "ğŸ“š ë¬¸í•™ê°€", "field": "ë¬¸í•™ì°½ì‘", "level": "ë°•ì‚¬ê¸‰"},
            "science": {"name": "ğŸ”¬ ê³¼í•™ì", "field": "ê³¼í•™ì—°êµ¬", "level": "ë°•ì‚¬ê¸‰"},
            "cooking": {"name": "ğŸ³ ìš”ë¦¬ì‚¬", "field": "ìš”ë¦¬ì˜ˆìˆ ", "level": "ë°•ì‚¬ê¸‰"},
            "travel": {"name": "âœˆï¸ ì—¬í–‰ê°€", "field": "ì—¬í–‰ê¸°íš", "level": "ë°•ì‚¬ê¸‰"},
            "health": {"name": "ğŸƒ ê±´ê°•ì‚¬", "field": "ê±´ê°•ê´€ë¦¬", "level": "ë°•ì‚¬ê¸‰"},
            # ì‹ ê·œ 16ëª… (v11.0 ì¶”ê°€)
            "ai_researcher": {
                "name": "ğŸ¤– AIì—°êµ¬ì",
                "field": "ì¸ê³µì§€ëŠ¥",
                "level": "ë…¸ë²¨ê¸‰",
            },
            "quantum": {
                "name": "âš›ï¸ ì–‘ìë¬¼ë¦¬í•™ì",
                "field": "ì–‘ìì»´í“¨íŒ…",
                "level": "ë…¸ë²¨ê¸‰",
            },
            "biotech": {
                "name": "ğŸ§¬ ë°”ì´ì˜¤í…Œí¬",
                "field": "ìƒëª…ê³µí•™",
                "level": "ë…¸ë²¨ê¸‰",
            },
            "space": {"name": "ğŸš€ ìš°ì£¼í•™ì", "field": "ìš°ì£¼ê³¼í•™", "level": "ë…¸ë²¨ê¸‰"},
            "climate": {"name": "ğŸŒ ê¸°í›„í•™ì", "field": "ê¸°í›„ë³€í™”", "level": "ë…¸ë²¨ê¸‰"},
            "neuro": {"name": "ğŸ§  ë‡Œê³¼í•™ì", "field": "ì‹ ê²½ê³¼í•™", "level": "ë…¸ë²¨ê¸‰"},
            "crypto": {"name": "â‚¿ ì•”í˜¸í•™ì", "field": "ë¸”ë¡ì²´ì¸", "level": "ì „ì„¤ê¸‰"},
            "metaverse": {
                "name": "ğŸŒ ë©”íƒ€ë²„ìŠ¤",
                "field": "ê°€ìƒí˜„ì‹¤",
                "level": "ì „ì„¤ê¸‰",
            },
            "sustainability": {
                "name": "â™»ï¸ ì§€ì†ê°€ëŠ¥",
                "field": "ì§€ì†ê²½ì˜",
                "level": "ì „ì„¤ê¸‰",
            },
            "data_scientist": {
                "name": "ğŸ“Š ë°ì´í„°í•™ì",
                "field": "ë¹…ë°ì´í„°",
                "level": "ì „ì„¤ê¸‰",
            },
            "social_impact": {
                "name": "ğŸ¤ ì‚¬íšŒí˜ì‹ ",
                "field": "ì‚¬íšŒë¬¸ì œ",
                "level": "ì „ì„¤ê¸‰",
            },
            "future_trend": {
                "name": "ğŸ”® ë¯¸ë˜í•™ì",
                "field": "ë¯¸ë˜ì˜ˆì¸¡",
                "level": "ì „ì„¤ê¸‰",
            },
            "innovation": {"name": "ğŸ’¡ í˜ì‹ ê°€", "field": "í˜ì‹ ì „ëµ", "level": "ì „ì„¤ê¸‰"},
            "philosopher": {
                "name": "ğŸ¤” ì² í•™ì",
                "field": "ì² í•™ì‚¬ìƒ",
                "level": "ì „ì„¤ê¸‰",
            },
            "linguist": {"name": "ğŸ—£ï¸ ì–¸ì–´í•™ì", "field": "ì–¸ì–´ë¶„ì„", "level": "ì „ì„¤ê¸‰"},
            "anthropologist": {
                "name": "ğŸ›ï¸ ì¸ë¥˜í•™ì",
                "field": "ë¬¸í™”ì—°êµ¬",
                "level": "ì „ì„¤ê¸‰",
            },
        }

        return experts

    def _init_database(self):
        """SQLite ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (Vercel í™˜ê²½ ìµœì í™”)"""
        try:
            # Vercel í™˜ê²½ì—ì„œëŠ” /tmp ë””ë ‰í† ë¦¬ ì‚¬ìš©
            import tempfile
            if not os.path.exists(os.path.dirname(self.db_file)):
                # ì„ì‹œ ë””ë ‰í† ë¦¬ì— ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
                temp_dir = tempfile.gettempdir()
                self.db_file = os.path.join(temp_dir, "advanced_memory_v11.db")
            
            conn = sqlite3.connect(self.db_file)
            cursor = conn.cursor()

            # í…Œì´ë¸” ìƒì„±
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS conversations (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    conversation_id TEXT,
                    user_message TEXT,
                    bot_response TEXT,
                    emotion TEXT,
                    expert TEXT,
                    timestamp REAL,
                    context_data TEXT
                )
            """
            )

            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS feedback (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    conversation_id TEXT,
                    message_id TEXT,
                    feedback_type TEXT,
                    rating INTEGER,
                    comment TEXT,
                    timestamp REAL
                )
            """
            )

            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS learning_patterns (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    pattern_type TEXT,
                    pattern_data TEXT,
                    confidence REAL,
                    usage_count INTEGER,
                    last_updated REAL
                )
            """
            )

            conn.commit()
            conn.close()
            print(f"ğŸ“ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ: {self.db_file}")
            
        except Exception as e:
            print(f"âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨ (ë©”ëª¨ë¦¬ ëª¨ë“œë¡œ ì „í™˜): {e}")
            # ë©”ëª¨ë¦¬ ëª¨ë“œë¡œ ì „í™˜
            self.db_file = ":memory:"

    def add_feedback(
        self,
        conversation_id: str,
        message_id: str,
        feedback_type: FeedbackType,
        rating: int,
        comment: str = "",
    ):
        """ì‚¬ìš©ì í”¼ë“œë°± ì¶”ê°€ ë° ì‹¤ì‹œê°„ í•™ìŠµ"""

        feedback = UserFeedback(
            conversation_id=conversation_id,
            message_id=message_id,
            feedback_type=feedback_type,
            rating=rating,
            comment=comment,
            timestamp=time.time(),
        )

        self.feedback_history.append(feedback)

        # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        conn = sqlite3.connect(self.db_file)
        cursor = conn.cursor()
        cursor.execute(
            """
            INSERT INTO feedback (conversation_id, message_id, feedback_type, rating, comment, timestamp)
            VALUES (?, ?, ?, ?, ?, ?)
        """,
            (
                conversation_id,
                message_id,
                feedback_type.value,
                rating,
                comment,
                feedback.timestamp,
            ),
        )
        conn.commit()
        conn.close()

        # ğŸ”„ ì‹¤ì‹œê°„ í•™ìŠµ ì‹¤í–‰
        self._real_time_learning(feedback)

        print(f"ğŸ“ í”¼ë“œë°± ì €ì¥ë¨: {feedback_type.value} (í‰ì : {rating})")

    def _real_time_learning(self, feedback: UserFeedback):
        """ì‹¤ì‹œê°„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜"""

        # 1. ì‘ë‹µ í’ˆì§ˆ íŒ¨í„´ í•™ìŠµ
        if feedback.rating >= 4:  # ì¢‹ì€ í”¼ë“œë°±
            self._reinforce_positive_pattern(feedback)
        elif feedback.rating <= 2:  # ë‚˜ìœ í”¼ë“œë°±
            self._adjust_negative_pattern(feedback)

        # 2. ì „ë¬¸ê°€ ì„±ëŠ¥ ì—…ë°ì´íŠ¸
        self._update_expert_performance(feedback)

        # 3. ì ì‘ ê·œì¹™ ìƒì„±/ìˆ˜ì •
        self._generate_adaptation_rules(feedback)

    def _reinforce_positive_pattern(self, feedback: UserFeedback):
        """ê¸ì •ì  íŒ¨í„´ ê°•í™”"""
        pattern_key = f"positive_{feedback.conversation_id}"

        if pattern_key not in self.pattern_learning:
            self.pattern_learning[pattern_key] = {
                "type": "positive_reinforcement",
                "confidence": 0.1,
                "examples": [],
                "characteristics": [],
            }

        # ì‹ ë¢°ë„ ì¦ê°€
        self.pattern_learning[pattern_key]["confidence"] = min(
            self.pattern_learning[pattern_key]["confidence"] + 0.1, 1.0
        )

        print(f"âœ… ê¸ì • íŒ¨í„´ ê°•í™”: {pattern_key}")

    def _adjust_negative_pattern(self, feedback: UserFeedback):
        """ë¶€ì •ì  íŒ¨í„´ ì¡°ì •"""
        pattern_key = f"negative_{feedback.conversation_id}"

        # ê°œì„  ë°©í–¥ ê²°ì •
        if feedback.feedback_type == FeedbackType.MORE_DETAIL:
            self._add_adaptation_rule("increase_detail", feedback.conversation_id)
        elif feedback.feedback_type == FeedbackType.SIMPLER:
            self._add_adaptation_rule("simplify_response", feedback.conversation_id)
        elif feedback.feedback_type == FeedbackType.IRRELEVANT:
            self._add_adaptation_rule("improve_relevance", feedback.conversation_id)

        print(f"ğŸ”§ ë¶€ì • íŒ¨í„´ ì¡°ì •: {feedback.feedback_type.value}")

    def _add_adaptation_rule(self, rule_type: str, conversation_id: str):
        """ì ì‘ ê·œì¹™ ì¶”ê°€"""
        rule = {
            "type": rule_type,
            "conversation_id": conversation_id,
            "created": time.time(),
            "weight": 1.0,
        }

        self.adaptation_rules.append(rule)
        print(f"ğŸ“‹ ì ì‘ ê·œì¹™ ì¶”ê°€: {rule_type}")

    def _update_expert_performance(self, feedback: UserFeedback):
        """ì „ë¬¸ê°€ ì„±ëŠ¥ ì—…ë°ì´íŠ¸"""
        conversation_id = feedback.conversation_id
        rating = feedback.rating

        if conversation_id in self.context_sessions:
            context = self.context_sessions[conversation_id]
            for expert in context.expert_chain:
                if expert not in self.expert_performance:
                    self.expert_performance[expert] = {
                        "usage_count": 0,
                        "total_rating": 0,
                        "avg_rating": 0.0,
                        "feedback_count": 0,
                    }

                perf = self.expert_performance[expert]
                perf["usage_count"] += 1
                perf["total_rating"] += rating
                perf["feedback_count"] += 1
                perf["avg_rating"] = perf["total_rating"] / perf["feedback_count"]

                print(f"ğŸ“Š {expert} ì„±ëŠ¥ ì—…ë°ì´íŠ¸: {perf['avg_rating']:.2f}")

    def _generate_adaptation_rules(self, feedback: UserFeedback):
        """ì ì‘ ê·œì¹™ ìƒì„±"""
        # í”¼ë“œë°± ìœ í˜•ë³„ ê·œì¹™ ìƒì„±
        if feedback.feedback_type == FeedbackType.MORE_DETAIL:
            self._add_adaptation_rule("increase_detail", feedback.conversation_id)
        elif feedback.feedback_type == FeedbackType.SIMPLER:
            self._add_adaptation_rule("simplify_response", feedback.conversation_id)
        elif feedback.feedback_type == FeedbackType.IRRELEVANT:
            self._add_adaptation_rule("improve_relevance", feedback.conversation_id)
        elif feedback.rating >= 4:
            self._add_adaptation_rule("maintain_style", feedback.conversation_id)

    def select_best_experts(
        self, message: str, emotion: str, context: Optional[ConversationContext] = None
    ) -> List[str]:
        """ìƒí™©ì— ë§ëŠ” ìµœì  ì „ë¬¸ê°€ ì„ íƒ (3-5ëª…)"""

        # 1. í‚¤ì›Œë“œ ê¸°ë°˜ 1ì°¨ í•„í„°ë§
        keyword_matches = self._keyword_matching(message)

        # 2. ê°ì • ê¸°ë°˜ í•„í„°ë§
        emotion_matches = self._emotion_expert_matching(emotion)

        # 3. ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ í•„í„°ë§ (ì—°ì† ëŒ€í™”)
        context_matches = []
        if context:
            context_matches = self._context_expert_matching(context)

        # 4. ì„±ëŠ¥ ê¸°ë°˜ ì •ë ¬
        performance_scores = self._calculate_expert_scores(
            keyword_matches, emotion_matches, context_matches
        )

        # 5. ìƒìœ„ 3-5ëª… ì„ íƒ
        selected_experts = sorted(
            performance_scores.items(), key=lambda x: x[1], reverse=True
        )[:5]

        expert_names = [expert[0] for expert in selected_experts]

        print(f"ğŸ¯ ì„ íƒëœ ì „ë¬¸ê°€: {expert_names}")
        return expert_names

    def _keyword_matching(self, message: str) -> List[str]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ì „ë¬¸ê°€ ë§¤ì¹­"""
        message_lower = message.lower()

        keyword_map = {
            "counselor": ["ë§ˆìŒ", "ìŠ¤íŠ¸ë ˆìŠ¤", "ìƒë‹´", "ì‹¬ë¦¬", "ê°ì •", "ìš°ìš¸", "ë¶ˆì•ˆ"],
            "marketing": ["ë§ˆì¼€íŒ…", "ë¸Œëœë“œ", "ê´‘ê³ ", "í™ë³´", "íŒë§¤", "ê³ ê°"],
            "finance": ["íˆ¬ì", "ëˆ", "ì£¼ì‹", "ë¶€ë™ì‚°", "ê¸ˆìœµ", "ê²½ì œ", "ì¬í…Œí¬"],
            "medical": ["ê±´ê°•", "ë³‘ì›", "ì˜ì‚¬", "ì¹˜ë£Œ", "ì•½", "ì¦ìƒ", "ì§„ë£Œ"],
            "tech": ["í”„ë¡œê·¸ë˜ë°", "ê°œë°œ", "ì½”ë”©", "ì•±", "ì›¹ì‚¬ì´íŠ¸", "AI", "ê¸°ìˆ "],
            "ai_researcher": ["ì¸ê³µì§€ëŠ¥", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹", "AI", "ì•Œê³ ë¦¬ì¦˜"],
            "quantum": ["ì–‘ì", "í€€í…€", "ë¬¼ë¦¬í•™", "ì»´í“¨íŒ…"],
            "space": ["ìš°ì£¼", "ì²œì²´", "ë¡œì¼“", "í–‰ì„±", "ì€í•˜"],
            "philosophy": ["ì² í•™", "ì¡´ì¬", "ì¸ìƒ", "ì˜ë¯¸", "ê°€ì¹˜ê´€", "ìœ¤ë¦¬"],
        }

        matches = []
        for expert, keywords in keyword_map.items():
            if any(keyword in message_lower for keyword in keywords):
                matches.append(expert)

        return matches

    def _emotion_expert_matching(self, emotion: str) -> List[str]:
        """ê°ì •ë³„ ìµœì  ì „ë¬¸ê°€ ë§¤ì¹­"""
        emotion_map = {
            "sad": ["counselor", "philosopher", "health"],
            "worried": ["counselor", "medical", "finance"],
            "angry": ["counselor", "legal", "philosopher"],
            "confused": ["education", "counselor", "philosopher"],
            "excited": ["creative", "innovation", "future_trend"],
            "happy": ["creative", "social_impact", "travel"],
            "grateful": ["philosopher", "social_impact", "counselor"],
        }

        return emotion_map.get(emotion, ["counselor"])

    def _context_expert_matching(self, context: ConversationContext) -> List[str]:
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì „ë¬¸ê°€ ë§¤ì¹­"""
        # ì´ì „ ì „ë¬¸ê°€ ì²´ì¸ ê³ ë ¤
        previous_experts = context.expert_chain

        # ì—°ê´€ ì „ë¬¸ê°€ ì¶”ì²œ
        related_map = {
            "marketing": ["business", "creative", "data_scientist"],
            "finance": ["business", "data_scientist", "future_trend"],
            "tech": ["ai_researcher", "data_scientist", "innovation"],
            "medical": ["biotech", "neuro", "health"],
            "education": ["innovation", "social_impact", "future_trend"],
        }

        suggestions = []
        for expert in previous_experts:
            if expert in related_map:
                suggestions.extend(related_map[expert])

        return list(set(suggestions))  # ì¤‘ë³µ ì œê±°

    def _calculate_expert_scores(
        self,
        keyword_matches: List[str],
        emotion_matches: List[str],
        context_matches: List[str],
    ) -> Dict[str, float]:
        """ì „ë¬¸ê°€ë³„ ì¢…í•© ì ìˆ˜ ê³„ì‚°"""
        scores = {}

        # ê¸°ë³¸ ì ìˆ˜ ì´ˆê¸°í™”
        for expert in self.experts.keys():
            scores[expert] = 0.0

        # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ (40%)
        for expert in keyword_matches:
            scores[expert] += 4.0

        # ê°ì • ë§¤ì¹­ ì ìˆ˜ (30%)
        for expert in emotion_matches:
            scores[expert] += 3.0

        # ì»¨í…ìŠ¤íŠ¸ ë§¤ì¹­ ì ìˆ˜ (20%)
        for expert in context_matches:
            scores[expert] += 2.0

        # ì„±ëŠ¥ ê¸°ë°˜ ë³´ë„ˆìŠ¤ (10%)
        for expert in self.expert_performance:
            performance = self.expert_performance[expert]
            avg_rating = performance.get("avg_rating", 3.0)
            scores[expert] += (avg_rating - 3.0) * 1.0

        return scores

    def create_conversation_context(
        self, conversation_id: str, mode: ConversationMode, topic: str
    ) -> ConversationContext:
        """ì—°ì† ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        context = ConversationContext(
            conversation_id=conversation_id,
            mode=mode,
            topic=topic,
            expert_chain=[],
            context_history=[],
            current_goal="ëŒ€í™” ì‹œì‘",
            progress=0.0,
            last_updated=time.time(),
        )

        self.context_sessions[conversation_id] = context
        print(f"ğŸ”„ ì—°ì† ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìƒì„±: {topic}")

        return context

    def update_conversation_context(
        self,
        conversation_id: str,
        message: str,
        response: str,
        expert: str,
        emotion: str,
    ):
        """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸"""
        if conversation_id not in self.context_sessions:
            return

        context = self.context_sessions[conversation_id]

        # ì „ë¬¸ê°€ ì²´ì¸ ì—…ë°ì´íŠ¸
        if expert not in context.expert_chain:
            context.expert_chain.append(expert)

        # íˆìŠ¤í† ë¦¬ ì¶”ê°€
        context.context_history.append(
            {
                "message": message,
                "response": response,
                "expert": expert,
                "emotion": emotion,
                "timestamp": time.time(),
            }
        )

        # ì§„í–‰ë„ ì—…ë°ì´íŠ¸
        context.progress = min(context.progress + 0.1, 1.0)
        context.last_updated = time.time()

        print(f"ğŸ”„ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸: {expert} ì°¸ì—¬")

    def generate_contextual_response(
        self, message: str, expert: str, context: Optional[ConversationContext] = None
    ) -> str:
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‘ë‹µ ìƒì„±"""
        base_response = self._generate_expert_response(message, expert)

        if not context or not context.context_history:
            return base_response

        # ì—°ì†ì„± ì¶”ê°€
        continuity_phrase = self._generate_continuity_phrase(context)

        # ì ì‘ ê·œì¹™ ì ìš©
        adapted_response = self._apply_adaptation_rules(
            base_response, context.conversation_id
        )

        return f"{continuity_phrase} {adapted_response}"

    def _generate_continuity_phrase(self, context: ConversationContext) -> str:
        """ì—°ì†ì„± ë¬¸êµ¬ ìƒì„±"""
        if len(context.context_history) == 1:
            return "ì•ì„œ ë§ì”€í•˜ì‹  ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ,"
        elif len(context.context_history) <= 3:
            return "ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ë¥¼ ì¢…í•©í•´ë³´ë©´,"
        else:
            return "ì „ì²´ì ì¸ ë§¥ë½ì—ì„œ ë³´ë©´,"

    def _apply_adaptation_rules(self, response: str, conversation_id: str) -> str:
        """ì ì‘ ê·œì¹™ ì ìš©"""
        adapted = response

        for rule in self.adaptation_rules:
            if rule["conversation_id"] == conversation_id:
                if rule["type"] == "increase_detail":
                    adapted += " (ë” ìì„¸í•œ ì„¤ëª…ì„ ì›í•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.)"
                elif rule["type"] == "simplify_response":
                    adapted = self._simplify_text(adapted)
                elif rule["type"] == "improve_relevance":
                    adapted = f"êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€ë“œë¦¬ë©´, {adapted}"

        return adapted

    def _simplify_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ê°„ì†Œí™”"""
        # ê¸´ ë¬¸ì¥ì„ ì§§ê²Œ ë¶„í• 
        sentences = text.split(".")
        if len(sentences) > 2:
            return ". ".join(sentences[:2]) + "."
        return text

    def _generate_expert_response(self, message: str, expert: str) -> str:
        """ì „ë¬¸ê°€ë³„ íŠ¹í™” ì‘ë‹µ ìƒì„±"""
        expert_info = self.experts.get(expert, {})
        expert_name = expert_info.get("name", "ì „ë¬¸ê°€")

        # ì „ë¬¸ê°€ë³„ ê¸°ë³¸ ì‘ë‹µ í…œí”Œë¦¿
        response_templates = {
            "counselor": f"{expert_name}ë¡œì„œ, ë§ˆìŒì„ í¸ì•ˆí•˜ê²Œ ê°–ê³  í•¨ê»˜ í•´ê²°í•´ë´ìš”.",
            "ai_researcher": f"{expert_name}ë¡œì„œ, ìµœì‹  AI ê¸°ìˆ  ê´€ì ì—ì„œ ë¶„ì„í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
            "quantum": f"{expert_name}ë¡œì„œ, ì–‘ìì—­í•™ì  ì ‘ê·¼ìœ¼ë¡œ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
            "philosopher": f"{expert_name}ë¡œì„œ, ì² í•™ì  ê´€ì ì—ì„œ ê¹Šì´ ìƒê°í•´ë´…ì‹œë‹¤.",
        }

        return response_templates.get(expert, f"{expert_name}ë¡œì„œ ë„ì›€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.")

    def get_learning_insights(self) -> Dict[str, Any]:
        """í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ"""
        return {
            "total_feedback": len(self.feedback_history),
            "avg_rating": self._calculate_avg_rating(),
            "learning_patterns": len(self.pattern_learning),
            "adaptation_rules": len(self.adaptation_rules),
            "expert_count": len(self.experts),
            "active_contexts": len(self.context_sessions),
        }

    def _calculate_avg_rating(self) -> float:
        """í‰ê·  í‰ì  ê³„ì‚°"""
        if not self.feedback_history:
            return 0.0

        total_rating = sum(f.rating for f in self.feedback_history)
        return round(total_rating / len(self.feedback_history), 2)

    def save_memory(self) -> bool:
        """ë©”ëª¨ë¦¬ ì €ì¥"""
        try:
            data = {
                "conversation_history": self.conversation_history,
                "user_preferences": self.user_preferences,
                "pattern_learning": self.pattern_learning,
                "expert_performance": self.expert_performance,
                "adaptation_rules": self.adaptation_rules,
                "experts": self.experts,
                "version": "11.0",
                "last_updated": time.time(),
            }

            with open(self.memory_file, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            print(f"ğŸ§  ë©”ëª¨ë¦¬ ì €ì¥ ì™„ë£Œ (v11.0)")
            return True
        except Exception as e:
            print(f"âŒ ë©”ëª¨ë¦¬ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def load_memory(self) -> bool:
        """ë©”ëª¨ë¦¬ ë¡œë“œ"""
        try:
            if os.path.exists(self.memory_file):
                with open(self.memory_file, "r", encoding="utf-8") as f:
                    data = json.load(f)

                self.conversation_history = data.get("conversation_history", [])
                self.user_preferences = data.get("user_preferences", {})
                self.pattern_learning = data.get("pattern_learning", {})
                self.expert_performance = data.get("expert_performance", {})
                self.adaptation_rules = data.get("adaptation_rules", [])

                print(f"ğŸ§  ë©”ëª¨ë¦¬ ë¡œë“œ ì™„ë£Œ: {len(self.conversation_history)}ê°œ ëŒ€í™”")
                return True
            else:
                print("ğŸ§  ìƒˆë¡œìš´ ë©”ëª¨ë¦¬ íŒŒì¼ ìƒì„±")
                return True
        except Exception as e:
            print(f"âŒ ë©”ëª¨ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # v11.0 ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    advanced_system = AdvancedMemorySystem()

    # ì—°ì† ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    context = advanced_system.create_conversation_context(
        "test_session", ConversationMode.CONTINUOUS, "AIì™€ ë¯¸ë˜ ê¸°ìˆ "
    )

    # ìµœì  ì „ë¬¸ê°€ ì„ íƒ
    message = "ì¸ê³µì§€ëŠ¥ì´ ë¯¸ë˜ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹ ê¹Œìš”?"
    experts = advanced_system.select_best_experts(message, "excited", context)

    print(f"ğŸ’¬ ë©”ì‹œì§€: {message}")
    print(f"ğŸ¯ ì„ íƒëœ ì „ë¬¸ê°€: {experts}")

    # í”¼ë“œë°± ì¶”ê°€
    advanced_system.add_feedback(
        "test_session", "msg_001", FeedbackType.HELPFUL, 5, "ì •ë§ ìœ ìš©í•œ ë‹µë³€ì´ì—ˆì–´ìš”!"
    )

    # í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ
    insights = advanced_system.get_learning_insights()
    print(f"ğŸ“Š í•™ìŠµ í˜„í™©: {insights}")

    # ë©”ëª¨ë¦¬ ì €ì¥
    advanced_system.save_memory()
